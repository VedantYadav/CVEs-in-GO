{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Extract All Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_githb_page_issues(page_link):\n",
    "    content = urllib.request.urlopen(page_link)\n",
    "    data = content.read()\n",
    "    soup = bs(data,\"lxml\")\n",
    "    data = soup.findAll('a', {'class': 'link-gray-dark v-align-middle no-underline h4 js-navigation-open'})\n",
    "    issues_links = []\n",
    "    for link in data:\n",
    "        issues_links.append(\"https://www.github.com/\" + link.get('href'))\n",
    "    return issues_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_text(x):\n",
    "    return [re.sub('[^A-Za-z@]+', ' ', i).lower() for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPO = \"facebook/react-native\"\n",
    "REPO = \"facebook/watchman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_repo(REPO):\n",
    "    all_links = []\n",
    "    for i in range(100000):\n",
    "        print(\"PageNO : \", i)\n",
    "        url = site + REPO + query_page + str(i) + query_issues\n",
    "        temp = extract_page_issues(url)\n",
    "        all_links = all_links + temp\n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "    return list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_issues_links = extract_repo(REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.github.com//facebook/watchman/issues/649',\n",
       " 'https://www.github.com//facebook/watchman/issues/648',\n",
       " 'https://www.github.com//facebook/watchman/issues/647',\n",
       " 'https://www.github.com//facebook/watchman/issues/646',\n",
       " 'https://www.github.com//facebook/watchman/issues/644',\n",
       " 'https://www.github.com//facebook/watchman/issues/643',\n",
       " 'https://www.github.com//facebook/watchman/issues/642',\n",
       " 'https://www.github.com//facebook/watchman/issues/641',\n",
       " 'https://www.github.com//facebook/watchman/issues/640',\n",
       " 'https://www.github.com//facebook/watchman/issues/638',\n",
       " 'https://www.github.com//facebook/watchman/issues/633',\n",
       " 'https://www.github.com//facebook/watchman/issues/631',\n",
       " 'https://www.github.com//facebook/watchman/issues/630',\n",
       " 'https://www.github.com//facebook/watchman/issues/629',\n",
       " 'https://www.github.com//facebook/watchman/issues/628',\n",
       " 'https://www.github.com//facebook/watchman/issues/627',\n",
       " 'https://www.github.com//facebook/watchman/issues/626',\n",
       " 'https://www.github.com//facebook/watchman/issues/625',\n",
       " 'https://www.github.com//facebook/watchman/issues/623',\n",
       " 'https://www.github.com//facebook/watchman/issues/621',\n",
       " 'https://www.github.com//facebook/watchman/issues/620',\n",
       " 'https://www.github.com//facebook/watchman/issues/618',\n",
       " 'https://www.github.com//facebook/watchman/issues/617',\n",
       " 'https://www.github.com//facebook/watchman/issues/616',\n",
       " 'https://www.github.com//facebook/watchman/issues/613',\n",
       " 'https://www.github.com//facebook/watchman/issues/649',\n",
       " 'https://www.github.com//facebook/watchman/issues/648',\n",
       " 'https://www.github.com//facebook/watchman/issues/647',\n",
       " 'https://www.github.com//facebook/watchman/issues/646',\n",
       " 'https://www.github.com//facebook/watchman/issues/644',\n",
       " 'https://www.github.com//facebook/watchman/issues/643',\n",
       " 'https://www.github.com//facebook/watchman/issues/642',\n",
       " 'https://www.github.com//facebook/watchman/issues/641',\n",
       " 'https://www.github.com//facebook/watchman/issues/640',\n",
       " 'https://www.github.com//facebook/watchman/issues/638',\n",
       " 'https://www.github.com//facebook/watchman/issues/633',\n",
       " 'https://www.github.com//facebook/watchman/issues/631',\n",
       " 'https://www.github.com//facebook/watchman/issues/630',\n",
       " 'https://www.github.com//facebook/watchman/issues/629',\n",
       " 'https://www.github.com//facebook/watchman/issues/628',\n",
       " 'https://www.github.com//facebook/watchman/issues/627',\n",
       " 'https://www.github.com//facebook/watchman/issues/626',\n",
       " 'https://www.github.com//facebook/watchman/issues/625',\n",
       " 'https://www.github.com//facebook/watchman/issues/623',\n",
       " 'https://www.github.com//facebook/watchman/issues/621',\n",
       " 'https://www.github.com//facebook/watchman/issues/620',\n",
       " 'https://www.github.com//facebook/watchman/issues/618',\n",
       " 'https://www.github.com//facebook/watchman/issues/617',\n",
       " 'https://www.github.com//facebook/watchman/issues/616',\n",
       " 'https://www.github.com//facebook/watchman/issues/613',\n",
       " 'https://www.github.com//facebook/watchman/issues/612',\n",
       " 'https://www.github.com//facebook/watchman/issues/611',\n",
       " 'https://www.github.com//facebook/watchman/issues/610',\n",
       " 'https://www.github.com//facebook/watchman/issues/609',\n",
       " 'https://www.github.com//facebook/watchman/issues/608',\n",
       " 'https://www.github.com//facebook/watchman/issues/607',\n",
       " 'https://www.github.com//facebook/watchman/issues/606',\n",
       " 'https://www.github.com//facebook/watchman/issues/605',\n",
       " 'https://www.github.com//facebook/watchman/issues/604',\n",
       " 'https://www.github.com//facebook/watchman/issues/602',\n",
       " 'https://www.github.com//facebook/watchman/issues/601',\n",
       " 'https://www.github.com//facebook/watchman/issues/599',\n",
       " 'https://www.github.com//facebook/watchman/issues/598',\n",
       " 'https://www.github.com//facebook/watchman/issues/597',\n",
       " 'https://www.github.com//facebook/watchman/issues/596',\n",
       " 'https://www.github.com//facebook/watchman/issues/595',\n",
       " 'https://www.github.com//facebook/watchman/issues/594',\n",
       " 'https://www.github.com//facebook/watchman/issues/593',\n",
       " 'https://www.github.com//facebook/watchman/issues/591',\n",
       " 'https://www.github.com//facebook/watchman/issues/590',\n",
       " 'https://www.github.com//facebook/watchman/issues/589',\n",
       " 'https://www.github.com//facebook/watchman/issues/587',\n",
       " 'https://www.github.com//facebook/watchman/issues/585',\n",
       " 'https://www.github.com//facebook/watchman/issues/583',\n",
       " 'https://www.github.com//facebook/watchman/issues/579',\n",
       " 'https://www.github.com//facebook/watchman/issues/577',\n",
       " 'https://www.github.com//facebook/watchman/issues/573',\n",
       " 'https://www.github.com//facebook/watchman/issues/572',\n",
       " 'https://www.github.com//facebook/watchman/issues/571',\n",
       " 'https://www.github.com//facebook/watchman/issues/570',\n",
       " 'https://www.github.com//facebook/watchman/issues/569',\n",
       " 'https://www.github.com//facebook/watchman/issues/568',\n",
       " 'https://www.github.com//facebook/watchman/issues/567',\n",
       " 'https://www.github.com//facebook/watchman/issues/566',\n",
       " 'https://www.github.com//facebook/watchman/issues/564',\n",
       " 'https://www.github.com//facebook/watchman/issues/563',\n",
       " 'https://www.github.com//facebook/watchman/issues/562',\n",
       " 'https://www.github.com//facebook/watchman/issues/561',\n",
       " 'https://www.github.com//facebook/watchman/issues/558',\n",
       " 'https://www.github.com//facebook/watchman/issues/556',\n",
       " 'https://www.github.com//facebook/watchman/issues/554',\n",
       " 'https://www.github.com//facebook/watchman/issues/553',\n",
       " 'https://www.github.com//facebook/watchman/issues/552',\n",
       " 'https://www.github.com//facebook/watchman/issues/551',\n",
       " 'https://www.github.com//facebook/watchman/issues/550',\n",
       " 'https://www.github.com//facebook/watchman/issues/548',\n",
       " 'https://www.github.com//facebook/watchman/issues/547',\n",
       " 'https://www.github.com//facebook/watchman/issues/546',\n",
       " 'https://www.github.com//facebook/watchman/issues/545',\n",
       " 'https://www.github.com//facebook/watchman/issues/543',\n",
       " 'https://www.github.com//facebook/watchman/issues/542',\n",
       " 'https://www.github.com//facebook/watchman/issues/541',\n",
       " 'https://www.github.com//facebook/watchman/issues/540',\n",
       " 'https://www.github.com//facebook/watchman/issues/539',\n",
       " 'https://www.github.com//facebook/watchman/issues/536',\n",
       " 'https://www.github.com//facebook/watchman/issues/535',\n",
       " 'https://www.github.com//facebook/watchman/issues/534',\n",
       " 'https://www.github.com//facebook/watchman/issues/533',\n",
       " 'https://www.github.com//facebook/watchman/issues/532',\n",
       " 'https://www.github.com//facebook/watchman/issues/531',\n",
       " 'https://www.github.com//facebook/watchman/issues/530',\n",
       " 'https://www.github.com//facebook/watchman/issues/529',\n",
       " 'https://www.github.com//facebook/watchman/issues/528',\n",
       " 'https://www.github.com//facebook/watchman/issues/525',\n",
       " 'https://www.github.com//facebook/watchman/issues/524',\n",
       " 'https://www.github.com//facebook/watchman/issues/523',\n",
       " 'https://www.github.com//facebook/watchman/issues/522',\n",
       " 'https://www.github.com//facebook/watchman/issues/521',\n",
       " 'https://www.github.com//facebook/watchman/issues/519',\n",
       " 'https://www.github.com//facebook/watchman/issues/518',\n",
       " 'https://www.github.com//facebook/watchman/issues/515',\n",
       " 'https://www.github.com//facebook/watchman/issues/514',\n",
       " 'https://www.github.com//facebook/watchman/issues/512',\n",
       " 'https://www.github.com//facebook/watchman/issues/511',\n",
       " 'https://www.github.com//facebook/watchman/issues/510',\n",
       " 'https://www.github.com//facebook/watchman/issues/509',\n",
       " 'https://www.github.com//facebook/watchman/issues/508',\n",
       " 'https://www.github.com//facebook/watchman/issues/507',\n",
       " 'https://www.github.com//facebook/watchman/issues/506',\n",
       " 'https://www.github.com//facebook/watchman/issues/503',\n",
       " 'https://www.github.com//facebook/watchman/issues/501',\n",
       " 'https://www.github.com//facebook/watchman/issues/500',\n",
       " 'https://www.github.com//facebook/watchman/issues/499',\n",
       " 'https://www.github.com//facebook/watchman/issues/498',\n",
       " 'https://www.github.com//facebook/watchman/issues/496',\n",
       " 'https://www.github.com//facebook/watchman/issues/495',\n",
       " 'https://www.github.com//facebook/watchman/issues/494',\n",
       " 'https://www.github.com//facebook/watchman/issues/492',\n",
       " 'https://www.github.com//facebook/watchman/issues/491',\n",
       " 'https://www.github.com//facebook/watchman/issues/490',\n",
       " 'https://www.github.com//facebook/watchman/issues/489',\n",
       " 'https://www.github.com//facebook/watchman/issues/488',\n",
       " 'https://www.github.com//facebook/watchman/issues/487',\n",
       " 'https://www.github.com//facebook/watchman/issues/486',\n",
       " 'https://www.github.com//facebook/watchman/issues/485',\n",
       " 'https://www.github.com//facebook/watchman/issues/484',\n",
       " 'https://www.github.com//facebook/watchman/issues/483',\n",
       " 'https://www.github.com//facebook/watchman/issues/481',\n",
       " 'https://www.github.com//facebook/watchman/issues/480',\n",
       " 'https://www.github.com//facebook/watchman/issues/479',\n",
       " 'https://www.github.com//facebook/watchman/issues/475',\n",
       " 'https://www.github.com//facebook/watchman/issues/474',\n",
       " 'https://www.github.com//facebook/watchman/issues/469',\n",
       " 'https://www.github.com//facebook/watchman/issues/467',\n",
       " 'https://www.github.com//facebook/watchman/issues/466',\n",
       " 'https://www.github.com//facebook/watchman/issues/464',\n",
       " 'https://www.github.com//facebook/watchman/issues/463',\n",
       " 'https://www.github.com//facebook/watchman/issues/462',\n",
       " 'https://www.github.com//facebook/watchman/issues/461',\n",
       " 'https://www.github.com//facebook/watchman/issues/460',\n",
       " 'https://www.github.com//facebook/watchman/issues/458',\n",
       " 'https://www.github.com//facebook/watchman/issues/454',\n",
       " 'https://www.github.com//facebook/watchman/issues/450',\n",
       " 'https://www.github.com//facebook/watchman/issues/449',\n",
       " 'https://www.github.com//facebook/watchman/issues/448',\n",
       " 'https://www.github.com//facebook/watchman/issues/447',\n",
       " 'https://www.github.com//facebook/watchman/issues/446',\n",
       " 'https://www.github.com//facebook/watchman/issues/445',\n",
       " 'https://www.github.com//facebook/watchman/issues/444',\n",
       " 'https://www.github.com//facebook/watchman/issues/443',\n",
       " 'https://www.github.com//facebook/watchman/issues/442',\n",
       " 'https://www.github.com//facebook/watchman/issues/441',\n",
       " 'https://www.github.com//facebook/watchman/issues/440',\n",
       " 'https://www.github.com//facebook/watchman/issues/439',\n",
       " 'https://www.github.com//facebook/watchman/issues/438',\n",
       " 'https://www.github.com//facebook/watchman/issues/434',\n",
       " 'https://www.github.com//facebook/watchman/issues/433',\n",
       " 'https://www.github.com//facebook/watchman/issues/432',\n",
       " 'https://www.github.com//facebook/watchman/issues/431',\n",
       " 'https://www.github.com//facebook/watchman/issues/430',\n",
       " 'https://www.github.com//facebook/watchman/issues/429',\n",
       " 'https://www.github.com//facebook/watchman/issues/428',\n",
       " 'https://www.github.com//facebook/watchman/issues/426',\n",
       " 'https://www.github.com//facebook/watchman/issues/423',\n",
       " 'https://www.github.com//facebook/watchman/issues/421',\n",
       " 'https://www.github.com//facebook/watchman/issues/420',\n",
       " 'https://www.github.com//facebook/watchman/issues/416',\n",
       " 'https://www.github.com//facebook/watchman/issues/415',\n",
       " 'https://www.github.com//facebook/watchman/issues/414',\n",
       " 'https://www.github.com//facebook/watchman/issues/407',\n",
       " 'https://www.github.com//facebook/watchman/issues/402',\n",
       " 'https://www.github.com//facebook/watchman/issues/400',\n",
       " 'https://www.github.com//facebook/watchman/issues/397',\n",
       " 'https://www.github.com//facebook/watchman/issues/396',\n",
       " 'https://www.github.com//facebook/watchman/issues/392',\n",
       " 'https://www.github.com//facebook/watchman/issues/390',\n",
       " 'https://www.github.com//facebook/watchman/issues/389',\n",
       " 'https://www.github.com//facebook/watchman/issues/388',\n",
       " 'https://www.github.com//facebook/watchman/issues/386',\n",
       " 'https://www.github.com//facebook/watchman/issues/385',\n",
       " 'https://www.github.com//facebook/watchman/issues/384',\n",
       " 'https://www.github.com//facebook/watchman/issues/383',\n",
       " 'https://www.github.com//facebook/watchman/issues/382',\n",
       " 'https://www.github.com//facebook/watchman/issues/381',\n",
       " 'https://www.github.com//facebook/watchman/issues/377',\n",
       " 'https://www.github.com//facebook/watchman/issues/376',\n",
       " 'https://www.github.com//facebook/watchman/issues/374',\n",
       " 'https://www.github.com//facebook/watchman/issues/373',\n",
       " 'https://www.github.com//facebook/watchman/issues/372',\n",
       " 'https://www.github.com//facebook/watchman/issues/371',\n",
       " 'https://www.github.com//facebook/watchman/issues/369',\n",
       " 'https://www.github.com//facebook/watchman/issues/364',\n",
       " 'https://www.github.com//facebook/watchman/issues/361',\n",
       " 'https://www.github.com//facebook/watchman/issues/358',\n",
       " 'https://www.github.com//facebook/watchman/issues/357',\n",
       " 'https://www.github.com//facebook/watchman/issues/355',\n",
       " 'https://www.github.com//facebook/watchman/issues/351',\n",
       " 'https://www.github.com//facebook/watchman/issues/350',\n",
       " 'https://www.github.com//facebook/watchman/issues/349',\n",
       " 'https://www.github.com//facebook/watchman/issues/339',\n",
       " 'https://www.github.com//facebook/watchman/issues/326',\n",
       " 'https://www.github.com//facebook/watchman/issues/324',\n",
       " 'https://www.github.com//facebook/watchman/issues/322',\n",
       " 'https://www.github.com//facebook/watchman/issues/319',\n",
       " 'https://www.github.com//facebook/watchman/issues/312',\n",
       " 'https://www.github.com//facebook/watchman/issues/305',\n",
       " 'https://www.github.com//facebook/watchman/issues/303',\n",
       " 'https://www.github.com//facebook/watchman/issues/302',\n",
       " 'https://www.github.com//facebook/watchman/issues/301',\n",
       " 'https://www.github.com//facebook/watchman/issues/300',\n",
       " 'https://www.github.com//facebook/watchman/issues/284',\n",
       " 'https://www.github.com//facebook/watchman/issues/268',\n",
       " 'https://www.github.com//facebook/watchman/issues/254',\n",
       " 'https://www.github.com//facebook/watchman/issues/249',\n",
       " 'https://www.github.com//facebook/watchman/issues/246',\n",
       " 'https://www.github.com//facebook/watchman/issues/245',\n",
       " 'https://www.github.com//facebook/watchman/issues/244',\n",
       " 'https://www.github.com//facebook/watchman/issues/241',\n",
       " 'https://www.github.com//facebook/watchman/issues/240',\n",
       " 'https://www.github.com//facebook/watchman/issues/239',\n",
       " 'https://www.github.com//facebook/watchman/issues/238',\n",
       " 'https://www.github.com//facebook/watchman/issues/237',\n",
       " 'https://www.github.com//facebook/watchman/issues/236',\n",
       " 'https://www.github.com//facebook/watchman/issues/235',\n",
       " 'https://www.github.com//facebook/watchman/issues/234',\n",
       " 'https://www.github.com//facebook/watchman/issues/232',\n",
       " 'https://www.github.com//facebook/watchman/issues/230',\n",
       " 'https://www.github.com//facebook/watchman/issues/225',\n",
       " 'https://www.github.com//facebook/watchman/issues/222',\n",
       " 'https://www.github.com//facebook/watchman/issues/217',\n",
       " 'https://www.github.com//facebook/watchman/issues/214',\n",
       " 'https://www.github.com//facebook/watchman/issues/213',\n",
       " 'https://www.github.com//facebook/watchman/issues/212',\n",
       " 'https://www.github.com//facebook/watchman/issues/210',\n",
       " 'https://www.github.com//facebook/watchman/issues/207',\n",
       " 'https://www.github.com//facebook/watchman/issues/206',\n",
       " 'https://www.github.com//facebook/watchman/issues/205',\n",
       " 'https://www.github.com//facebook/watchman/issues/204',\n",
       " 'https://www.github.com//facebook/watchman/issues/202',\n",
       " 'https://www.github.com//facebook/watchman/issues/201',\n",
       " 'https://www.github.com//facebook/watchman/issues/197',\n",
       " 'https://www.github.com//facebook/watchman/issues/195',\n",
       " 'https://www.github.com//facebook/watchman/issues/194',\n",
       " 'https://www.github.com//facebook/watchman/issues/193',\n",
       " 'https://www.github.com//facebook/watchman/issues/188',\n",
       " 'https://www.github.com//facebook/watchman/issues/185',\n",
       " 'https://www.github.com//facebook/watchman/issues/184',\n",
       " 'https://www.github.com//facebook/watchman/issues/182',\n",
       " 'https://www.github.com//facebook/watchman/issues/181',\n",
       " 'https://www.github.com//facebook/watchman/issues/180',\n",
       " 'https://www.github.com//facebook/watchman/issues/179',\n",
       " 'https://www.github.com//facebook/watchman/issues/178',\n",
       " 'https://www.github.com//facebook/watchman/issues/176',\n",
       " 'https://www.github.com//facebook/watchman/issues/175',\n",
       " 'https://www.github.com//facebook/watchman/issues/172',\n",
       " 'https://www.github.com//facebook/watchman/issues/168',\n",
       " 'https://www.github.com//facebook/watchman/issues/167',\n",
       " 'https://www.github.com//facebook/watchman/issues/163',\n",
       " 'https://www.github.com//facebook/watchman/issues/158',\n",
       " 'https://www.github.com//facebook/watchman/issues/156',\n",
       " 'https://www.github.com//facebook/watchman/issues/155',\n",
       " 'https://www.github.com//facebook/watchman/issues/154',\n",
       " 'https://www.github.com//facebook/watchman/issues/153',\n",
       " 'https://www.github.com//facebook/watchman/issues/152',\n",
       " 'https://www.github.com//facebook/watchman/issues/147',\n",
       " 'https://www.github.com//facebook/watchman/issues/144',\n",
       " 'https://www.github.com//facebook/watchman/issues/143',\n",
       " 'https://www.github.com//facebook/watchman/issues/141',\n",
       " 'https://www.github.com//facebook/watchman/issues/139',\n",
       " 'https://www.github.com//facebook/watchman/issues/137',\n",
       " 'https://www.github.com//facebook/watchman/issues/135',\n",
       " 'https://www.github.com//facebook/watchman/issues/134',\n",
       " 'https://www.github.com//facebook/watchman/issues/133',\n",
       " 'https://www.github.com//facebook/watchman/issues/132',\n",
       " 'https://www.github.com//facebook/watchman/issues/125',\n",
       " 'https://www.github.com//facebook/watchman/issues/124',\n",
       " 'https://www.github.com//facebook/watchman/issues/123',\n",
       " 'https://www.github.com//facebook/watchman/issues/122',\n",
       " 'https://www.github.com//facebook/watchman/issues/121',\n",
       " 'https://www.github.com//facebook/watchman/issues/120',\n",
       " 'https://www.github.com//facebook/watchman/issues/119',\n",
       " 'https://www.github.com//facebook/watchman/issues/118',\n",
       " 'https://www.github.com//facebook/watchman/issues/117',\n",
       " 'https://www.github.com//facebook/watchman/issues/116',\n",
       " 'https://www.github.com//facebook/watchman/issues/115',\n",
       " 'https://www.github.com//facebook/watchman/issues/114',\n",
       " 'https://www.github.com//facebook/watchman/issues/113',\n",
       " 'https://www.github.com//facebook/watchman/issues/112',\n",
       " 'https://www.github.com//facebook/watchman/issues/111',\n",
       " 'https://www.github.com//facebook/watchman/issues/110',\n",
       " 'https://www.github.com//facebook/watchman/issues/109',\n",
       " 'https://www.github.com//facebook/watchman/issues/108',\n",
       " 'https://www.github.com//facebook/watchman/issues/107',\n",
       " 'https://www.github.com//facebook/watchman/issues/106',\n",
       " 'https://www.github.com//facebook/watchman/issues/105',\n",
       " 'https://www.github.com//facebook/watchman/issues/104',\n",
       " 'https://www.github.com//facebook/watchman/issues/103',\n",
       " 'https://www.github.com//facebook/watchman/issues/102',\n",
       " 'https://www.github.com//facebook/watchman/issues/101',\n",
       " 'https://www.github.com//facebook/watchman/issues/100',\n",
       " 'https://www.github.com//facebook/watchman/issues/98',\n",
       " 'https://www.github.com//facebook/watchman/issues/97',\n",
       " 'https://www.github.com//facebook/watchman/issues/96',\n",
       " 'https://www.github.com//facebook/watchman/issues/95',\n",
       " 'https://www.github.com//facebook/watchman/issues/91',\n",
       " 'https://www.github.com//facebook/watchman/issues/90',\n",
       " 'https://www.github.com//facebook/watchman/issues/89',\n",
       " 'https://www.github.com//facebook/watchman/issues/88',\n",
       " 'https://www.github.com//facebook/watchman/issues/87',\n",
       " 'https://www.github.com//facebook/watchman/issues/86',\n",
       " 'https://www.github.com//facebook/watchman/issues/85',\n",
       " 'https://www.github.com//facebook/watchman/issues/84',\n",
       " 'https://www.github.com//facebook/watchman/issues/82',\n",
       " 'https://www.github.com//facebook/watchman/issues/80',\n",
       " 'https://www.github.com//facebook/watchman/issues/79',\n",
       " 'https://www.github.com//facebook/watchman/issues/78',\n",
       " 'https://www.github.com//facebook/watchman/issues/77',\n",
       " 'https://www.github.com//facebook/watchman/issues/76',\n",
       " 'https://www.github.com//facebook/watchman/issues/75',\n",
       " 'https://www.github.com//facebook/watchman/issues/74',\n",
       " 'https://www.github.com//facebook/watchman/issues/72',\n",
       " 'https://www.github.com//facebook/watchman/issues/71',\n",
       " 'https://www.github.com//facebook/watchman/issues/70',\n",
       " 'https://www.github.com//facebook/watchman/issues/69',\n",
       " 'https://www.github.com//facebook/watchman/issues/68',\n",
       " 'https://www.github.com//facebook/watchman/issues/67',\n",
       " 'https://www.github.com//facebook/watchman/issues/65',\n",
       " 'https://www.github.com//facebook/watchman/issues/64',\n",
       " 'https://www.github.com//facebook/watchman/issues/63',\n",
       " 'https://www.github.com//facebook/watchman/issues/62',\n",
       " 'https://www.github.com//facebook/watchman/issues/60',\n",
       " 'https://www.github.com//facebook/watchman/issues/59',\n",
       " 'https://www.github.com//facebook/watchman/issues/58',\n",
       " 'https://www.github.com//facebook/watchman/issues/57',\n",
       " 'https://www.github.com//facebook/watchman/issues/55',\n",
       " 'https://www.github.com//facebook/watchman/issues/52',\n",
       " 'https://www.github.com//facebook/watchman/issues/50',\n",
       " 'https://www.github.com//facebook/watchman/issues/49',\n",
       " 'https://www.github.com//facebook/watchman/issues/48',\n",
       " 'https://www.github.com//facebook/watchman/issues/47',\n",
       " 'https://www.github.com//facebook/watchman/issues/46',\n",
       " 'https://www.github.com//facebook/watchman/issues/43',\n",
       " 'https://www.github.com//facebook/watchman/issues/42',\n",
       " 'https://www.github.com//facebook/watchman/issues/41',\n",
       " 'https://www.github.com//facebook/watchman/issues/39',\n",
       " 'https://www.github.com//facebook/watchman/issues/38',\n",
       " 'https://www.github.com//facebook/watchman/issues/36',\n",
       " 'https://www.github.com//facebook/watchman/issues/35',\n",
       " 'https://www.github.com//facebook/watchman/issues/34',\n",
       " 'https://www.github.com//facebook/watchman/issues/33',\n",
       " 'https://www.github.com//facebook/watchman/issues/32',\n",
       " 'https://www.github.com//facebook/watchman/issues/31',\n",
       " 'https://www.github.com//facebook/watchman/issues/30',\n",
       " 'https://www.github.com//facebook/watchman/issues/29',\n",
       " 'https://www.github.com//facebook/watchman/issues/27',\n",
       " 'https://www.github.com//facebook/watchman/issues/26',\n",
       " 'https://www.github.com//facebook/watchman/issues/25',\n",
       " 'https://www.github.com//facebook/watchman/issues/24',\n",
       " 'https://www.github.com//facebook/watchman/issues/22',\n",
       " 'https://www.github.com//facebook/watchman/issues/21',\n",
       " 'https://www.github.com//facebook/watchman/issues/20',\n",
       " 'https://www.github.com//facebook/watchman/issues/19',\n",
       " 'https://www.github.com//facebook/watchman/issues/17',\n",
       " 'https://www.github.com//facebook/watchman/issues/15',\n",
       " 'https://www.github.com//facebook/watchman/issues/14',\n",
       " 'https://www.github.com//facebook/watchman/issues/13',\n",
       " 'https://www.github.com//facebook/watchman/issues/12',\n",
       " 'https://www.github.com//facebook/watchman/issues/11',\n",
       " 'https://www.github.com//facebook/watchman/issues/9',\n",
       " 'https://www.github.com//facebook/watchman/issues/8',\n",
       " 'https://www.github.com//facebook/watchman/issues/7',\n",
       " 'https://www.github.com//facebook/watchman/issues/6',\n",
       " 'https://www.github.com//facebook/watchman/issues/2',\n",
       " 'https://www.github.com//facebook/watchman/issues/1']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_issues_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_snyk_issues(link=\"https://www.snyk.io/vuln/page/\"):\n",
    "    def extract_issues(link):\n",
    "        print(link)\n",
    "        iss = urllib.request.urlopen(link)\n",
    "        data_1 = iss.read()\n",
    "        soup_1 = bs(data_1,\"lxml\")\n",
    "        data_1 = soup_1.findAll('span',{'class':'l-push-left--sm'})\n",
    "        issues = []\n",
    "        for ele in data_1:\n",
    "            issues.append(\"https://www.snyk.io/\" + ele.find(\"a\").get('href'))\n",
    "        return issues\n",
    "    end = \"?type=golang\"\n",
    "    issues = []\n",
    "    for i in range(1000):\n",
    "        temp = extract_issues(link+str(i+1)+end)\n",
    "        issues = issues + temp \n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "    \n",
    "    git_link=[]\n",
    "    for i in issues:\n",
    "        print(i)\n",
    "        iss = urllib.request.urlopen(i)\n",
    "        data_1 = iss.read()\n",
    "        soup_1 = bs(data_1,\"lxml\")\n",
    "        data_1 = soup_1.findAll('div',{'class':'card card--markdown'})\n",
    "        for line in data_1:\n",
    "            for link in line.findAll(\"a\"):\n",
    "                temp = link.get(\"href\").replace(\"/\",\" \")\n",
    "                if \"issues\" in temp or \"pull\" in temp:\n",
    "                    git_link.append(link.get(\"href\"))\n",
    "    return list(set(git_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.snyk.io/vuln/page/1?type=golang\n",
      "https://www.snyk.io/vuln/page/2?type=golang\n",
      "https://www.snyk.io/vuln/page/3?type=golang\n",
      "https://www.snyk.io/vuln/page/4?type=golang\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOOGLEGVISORRUNSCBOOTFILTER-72291\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMMOBYMOBY-72364\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGRAFANAGRAFANA-72290\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGRAFANAGRAFANAPKGSERVICES-50088\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGRAFANAGRAFANAPKGAPI-50087\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMHASHICORPPACKERBUILDERAMAZONCOMMON-50085\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOOGLEFSCRYPTSECURITY-50084\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOOGLEFSCRYPTPAM-50083\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOGSGOGSROUTESUSER-50081\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMMINIOMINIOCMD-50080\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGDDOGOSRC-50079\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTSOURCETOIMAGEPKGTAR-50077\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMELASTICBEATSPACKETBEATPROTOSPGSQL-50076\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-CODECLOUDFOUNDRYORGGOROUTERROUTE-50074\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-CODECLOUDFOUNDRYORGGOROUTERPROXY-50075\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-CODECLOUDFOUNDRYORGARCHIVER-50073\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMMHOLTARCHIVERCMDARCHIVER-50071\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDPKGHTTPUTIL-50070\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDPKGHTTPUTIL-50069\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDETCDSERVER-50068\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDETCDSERVER-50067\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDETCDMAIN-50066\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDETCDMAIN-50065\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDEMBED-50064\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCOREOSETCDEMBED-50063\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMHEKETIHEKETIAPPSGLUSTERFS-50061\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMHEKETIHEKETIAPPSGLUSTERFS-50062\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMSNAPCORESNAPDDAEMON-50060\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMMIEKGDNS-50059\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMIPFSGOIPFSREPOCONFIG-50058\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMIPFSGOIPFSCONFIG-50054\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-CODECLOUDFOUNDRYORGGROOTFSFETCHERLAYERFETCHER-50057\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMBTCSUITERELEASESGOSOCKSSOCKS-50056\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMBTCSUITEGOSOCKSSOCKS-50055\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMREMIND101EMPIRE-50052\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLDAPLDAP-50053\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMROBBERT229JWT-50051\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDGRIJALVAJWTGO-50049\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMCLOUDFLAREGOLZ4-50050\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50029\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GOLANGORGXCRYPTOSSH-50032\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMBITLYOAUTH2PROXY-50015\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-K8SIOKUBERNETES-50004\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GOPKGINSQUAREGOJOSEV2-50048\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GOPKGINSQUAREGOJOSEV1-50003\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENCONTAINERSRUNCLIBCONTAINER-50017\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENCONTAINERSRUNCLIBCONTAINER-50027\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMAPPCDOCKER2ACILIB-50043\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GOPKGINSQUAREGOJOSEV1-50020\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMAPPCDOCKER2ACILIB-50031\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMPROJECTATOMICOCIREGISTERMACHINE-50040\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50028\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50016\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMLXCLXD-50039\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMLXCLXD-50041\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50023\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMBITLYOAUTH2PROXY-50013\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50022\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENCONTAINERSRUNCLIBCONTAINERUSER-50037\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50038\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50002\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-K8SIOKUBERNETES-50034\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50000\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50014\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-K8SIOKUBERNETES-50026\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50033\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERLIBCONTAINER-50012\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50044\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50045\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50046\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50047\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMOPENSHIFTORIGIN-50042\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-K8SIOKUBERNETES-50019\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50006\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50007\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50008\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOGITSGOGS-50030\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50010\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOGITSGOGS-50009\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50018\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOGITSGOGS-50005\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50024\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMDOCKERDOCKER-50001\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGITHUBHUB-50036\n",
      "https://www.snyk.io//vuln/SNYK-GOLANG-GITHUBCOMGOLANGGO-50011\n"
     ]
    }
   ],
   "source": [
    "links = extract_snyk_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_issues(link):\n",
    "    iss = urllib.request.urlopen(link)\n",
    "    data_1 = iss.read()\n",
    "    soup_1 = bs(data_1,\"lxml\")\n",
    "    data_1 = soup_1.findAll('td',{'class':'d-block comment-body markdown-body js-comment-body'})\n",
    "    data_1 = data_1 + soup_1.findAll(\"a\",{\"class\":\"title-link\"})\n",
    "    issues = []\n",
    "    code = []\n",
    "    code_list = []\n",
    "    for i in data_1:\n",
    "        issues.append(i.get_text())\n",
    "        code_list = code_list + i.findAll(\"code\")\n",
    "        code_list = code_list + i.findAll(\"pre\")\n",
    "    for ele in code_list:\n",
    "        code.append(ele.get_text())\n",
    "    for id_x in range(len(issues)):\n",
    "        for ele in code:\n",
    "            issues[id_x] = issues[id_x].replace(ele,\" \",1)\n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = []\n",
    "for i in links:\n",
    "    doc = doc + extract_issues(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nFixes #33173.\\n#31705 added   when setting up the docker client configuration, but this should also be applied to the daemon.\\nIf a file containing CAs for validating clients is provided, only the certs used in that file should be used to validate client connections, and not both the certs in that file and the system root certs.\\nIf the union of the system certs and the provided CA certs is desired, the additional CA certs should be added to the system pool, or the system certs added to the provided CA file.\\ncc @dmcgowan @thaJeztah\\nAlso cc @diogomonica for visibility\\n\\n',\n",
       " '\\nLGTM on green\\n',\n",
       " '\\n(sorry misspelled a word in a comment, fixed that :))\\n',\n",
       " '\\nLGTM\\n',\n",
       " '\\nCVE-2018-12608 was assigned to this issue.\\n',\n",
       " '\\n          [17.03] Patch go connections\\n          #28\\n',\n",
       " \"\\nDescription\\nIf   is used, the daemon accepts to many CA's.\\nSteps to reproduce the issue:\\n\\nstart docker daemon with:\\n  options\\nuse openssl to debug the ssl communication:\\n \\ncheck output for  :\\n\\nDescribe the results you received:\\n \\nThe first entry is my CA, but after that it seems all CA's found on the system is also acceptable\\nDescribe the results you expected:\\n \\nOnly the CA from the   setting should be a acceptable client certificate CA name\\nOutput of  :\\n \\nOutput of  :\\n \\n\",\n",
       " '\\n          Use exclusive root pools if a CA cert file is specified in the daemon\\n          #33182\\n',\n",
       " '\\nThis PR fixes XSS vulnerabilities in dashboard link components. This happens when you put html with XSS as a link title, like   in\\nPanel -> General -> Drilldown / detail link -> Title or\\nDashboard -> Links -> Tooltip\\n',\n",
       " '\\nHello, good to see a PR. I found this vulnerability when I typed XSS in the Drilldown / detail link in the title field. After filling in the title field the dashboard field was automatically filled with the same value (XSS). When adding the detail link and hovering over the information icon, the XSS was also executed.\\n',\n",
       " '\\n@1Jesper1 so could you confirm this PR fixes it?\\n',\n",
       " '\\nYes, this PR fixes it.\\n',\n",
       " '\\nI think we can cover several XSS issues by this PR.\\n',\n",
       " '\\nGood to see this issue fixed! When will this be rolled out?\\n',\n",
       " '\\n@1Jesper1 Currently targeted for the upcoming 5.2 release (no release date yet).\\n',\n",
       " '\\n          [v4.5.x] fix XSS vulnerabilities in dashboard links\\n          #12265\\n',\n",
       " '\\nMake \"owners\" field required on source_ami_filter.\\nCloses #6584\\n',\n",
       " '\\n👍\\n',\n",
       " '\\n👍\\n',\n",
       " '\\n          Move source_ami_filter owner to owners\\n          #44\\n',\n",
       " '\\nHashiCorp\\'s security team pointed out an interesting potential exploit where if you request an amazon AMI via a source_ami_filter, but don\\'t have \" \" selected, you can accidentally use a malicious base image instead of one from your own organization or a trusted vendor.\\nThe impact of making the \"owner\" field required would be low for the users (I strongly suspect that a majority of people using the filter already define the owner field) but could save users from making a potentially dangerous mistake. I think we should have Packer fail during validation with an error that says this field must be designated; if we decide that there is a valid use case where people may not want to have to set this field, we could potentially allow an opt out like setting \"owner\" to \"any\" but honestly I can\\'t think of a situation where this really makes a great deal of sense.\\nI\\'m going to slate this for v1.3.0 but I\\'d like to hear community thoughts.\\n',\n",
       " '\\n👍 to this, absolutely.\\nI encountered exactly this bug last week, ended up with a Monero miner instead of a vanilla Ubuntu AMI when the   filter was missed.\\n',\n",
       " '\\n@007 Can you shoot me an email? I have a couple of questions about your experience with this issue.\\n',\n",
       " '\\nDone\\n',\n",
       " \"\\n@SwampDragons I can't upgrade to Packer 1.3.0 because of this change. Essentially we use the same JSON Packer definitions for production AWS account as development AWS account, and only have to modify the   to toggle between production and development AWS credentials.\\nThe problem is the  s field id now is different as well for production and development AWS accounts. Can you provide a solution to this? Is there an abstraction I am missing? Thanks.\\n\",\n",
       " '\\n@nodesocket the \" s\" field is a list, so I believe you should be able to simply provide both possible \"owner\" IDs and have the filter still work for both. Then no matter which (prod or dev) owner owns the AMI, you should be able to find one.\\n',\n",
       " \"\\nAhh, didn't realize  s take a list. That worked. Thanks!\\n\",\n",
       " \"\\nAwesome! Super glad it isn't a blocker.\\n\",\n",
       " '\\nYou can also use  .\\nWe should probably add some more info in the docs. From the AWS docs:\\n\\nFilters the images by the  . Specify an AWS account ID,\\xa0self\\xa0(owner is the sender of the request), or an AWS owner alias (valid values are\\xa0amazon\\xa0|\\xa0aws-marketplace\\xa0|\\xa0microsoft\\xa0). Omitting this option returns all images for which you have launch permissions, regardless of  hip\\n\\nhttps://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html\\n',\n",
       " \"\\nGood point. I've opened a PR updating docs: #6694\\n\",\n",
       " '\\n          fix security hole with ami filter\\n          #6585\\n',\n",
       " '\\n          data-source/aws_ami and data-source/aws_ami_ids: Require  s argument\\n          #5576\\n',\n",
       " \"\\n          CVE-2018-15869: -- s flag isn't mandatory\\n          #3629\\n\",\n",
       " \"\\nI've added   to   (on Arch Linux) as described in the README:\\n \\nWith   enabled, I'm no longer in the   group after login for some reason, which means  I can no longer use  . Instead, it adds me to the root group:\\n \\nWith   commented out:\\n \\nLog:\\n \\nAny ideas? :)\\n\",\n",
       " '\\nAdd   to   instead. Auth module at bottom and session module  just below  :\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth      optional   .so\\n\\nsession    optional   pam_loginuid.so\\nsession    optional   pam_keyinit.so       force revoke\\nsession   optional   .so  drop_caches lock_policies\\nsession    include    system-auth\\n...\\n\\n',\n",
       " \"\\n@fancytenseletters Hmm, I just tried that but it doesn't make any difference unfortunately :( Same thing is still happening.\\nI removed it from   and changed   to:\\n#%PAM-1.0\\n\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth       optional    .so\\n\\naccount    required   pam_access.so\\naccount    required   pam_nologin.so\\naccount    include    system-auth\\n\\n    include    system-auth\\n\\nsession    optional   pam_loginuid.so\\nsession    optional    .so       force revoke\\nsession    optional    .so       drop_caches lock_policies\\nsession    include    system-auth\\nsession    optional   pam_motd.so          motd=/etc/motd\\nsession    optional   pam_mail.so          dir=/var/spool/mail standard quiet\\n#-session   optional    \\nsession    required   pam_env.so\\n\\n\",\n",
       " '\\n@Minecrell can you try uncommenting   and adding bypass for it (I assume you use systemd):\\n#%PAM-1.0\\n\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth       optional    .so\\n\\naccount    required   pam_access.so\\naccount    required   pam_nologin.so\\naccount    include    system-auth\\n\\n    include    system-auth\\n\\nsession    optional   pam_loginuid.so\\nsession    optional    .so       force revoke\\nsession [success=1 default=ignore]     service = systemd-user quiet\\nsession    optional    .so       drop_caches lock_policies\\nsession    include    system-auth\\nsession    optional   pam_motd.so          motd=/etc/motd\\nsession    optional   pam_mail.so          dir=/var/spool/mail standard quiet\\n-session   optional    \\nsession    required   pam_env.so\\n\\n',\n",
       " '\\n@fancytenseletters Yeah, I disabled   because it was causing   to be called twice for some reason, but it seems like your bypass using   fixes that too :) Thanks!\\nI copied your config as-is to  , but the problem persists: the user is still in the root group instead of   with  .so enabled.\\n',\n",
       " '\\nPerhaps there is some bug in  .\\nCould you post your     and log from login again?\\nAlso, can you try to create and encrypt some folder and try to relogin? How do you login? Console/sddm/lightdm/gdm?\\n',\n",
       " \"\\n@fancytenseletters Sure, I appreciate your help! :)\\nNormally I use lightdm, but for testing I have disabled it and just login from the default console login prompt. For some reason, login in lightdm is entirely broken with  . It seems to start logging in (screen turns black), but shortly after the login mask of lightdm appears again.\\nI've posted the files and logs (for console login and lightdm login) at https://gist.github.com/Minecrell/33fea177022b36313d357a3c5994b9d9\\nThe folder I created is unlocked correctly, but with console login the group is wrong and with lightdm it doesn't even log in properly.\\n\",\n",
       " '\\nDo you have https://www.archlinux.org/packages/extra/x86_64/accountsservice/ package installed?\\n',\n",
       " \"\\nI did not, but I just installed it and it doesn't make any difference either :(\\n\",\n",
       " '\\nI just realized I am also experiencing this bug. In my case, my user is not in the   group, preventing me from using USB devices in VirtualBox. I am also on Arch and using systemd (as default on Arch).\\n',\n",
       " '\\nShould we keep the  .so in   file for the   directive and move the other two to  ?\\nEDIT: I can confirm doing this change appears to fix the groups issue for me as well.\\n',\n",
       " '\\n@Minecrell can you confirm that adding     module to   fixes your issue?  Example below:\\npassword  required  pam_unix.so     try_first_pass sha512 shadow\\npassword  optional   .so\\npassword  optional  pam_permit.so\\n\\n',\n",
       " \"\\nDoesn't seem to make any difference for me :( I still get:\\n \\n... with these configs & logs: https://gist.github.com/Minecrell/53e478dc8495c93357a6bf38449fff39\\n\",\n",
       " '\\n@Minecrell I just compared your config files with mine and they look identical except for the   directive in one of the   entries. Sorry I cannot be of more help.\\n',\n",
       " \"\\nAs I was looking into reproducing #93 I managed to reproduce this bug. Here's a QEMU VM that triggers the bug running HEAD:\\nhttps://drive.google.com/open?id=1soLFKOoFHK47d31RCn6qmJB7AORe2ysg\\nUncompress (using xz, no tarball) and launch using virt-manager. Fedora 26 settings. Two users: root and qemu, both have the same  : qemu. User qemu's home is encrypted, PAM unlocking is setup.\\n\",\n",
       " '\\n@sebadoom, this is great, will investigate tonight.\\n',\n",
       " '\\nFor me, the simple change that makes this happen was when I added   to \"/etc/pam.d/systemd-user\" on my Ubuntu 18.04 (Bionic) system.\\nCurrently, the Ubuntu package does not run   for /etc/pam.d/common-session-noninteractive which is what systemd-user uses.  I was guessing this also means most of the background daemons on login don\\'t have access to the filesystem.\\nIn my attempt to resolve this I added pam.d to /etc/pam.d/systemd-user - whether I put it before or after systemd the login groups are messed up, and the session/user keys don\\'t end up linked.\\nMy understanding of PAM is really lacking at this point to understand that more.. it sounds like this is going to get replaced by systemd integration never the less thought I\\'d add the comment.\\n',\n",
       " '\\nI\\'ve realised part of the issue for me.. gnome-terminal is not actually running as a new process but is instead powered by \\'gnome-terminal-server\\' which runs under the systemd-user session .. so gnome-terminal itself and all commands you run inside of it are \"broken\" much like other services started by systemd-user in many configurations.\\n',\n",
       " '\\nI can reproduce this on a fresh Ubuntu 18.04 installation.  It happens for any PAM context where   is loaded (even if no filesystems are in use)\\n(1) Install 18.04 using http://cdimage.ubuntu.com/daily-live/current/bionic-desktop-amd64.iso\\n(2) apt-get install libpam-  fscrypt xterm\\n(3) Reboot (no need to do any fscrypt setup)\\n(4) Login, launch xterm, run \"id\" (no groups); compare to the output from \"Terminal\" (has groups); xterm (and anything else launched from gnome-shell) runs under the session scope but gnome-terminal runs under the user scope due to using gnome-terminal-server as a backend process.  Same issue occurs for anything launched from gnome-shell that requires a group, e.g. virt-manager, etc.. gnome-terminal is special because it\\'s really using a process under the systemd-user scope.  By default on Ubuntu, /etc/pam.d/systemd-user has neither   nor   (the latter is a bug, systemd upstream added it in 2016).\\n(5) If you then add   (for session) into /etc/pam.d/systemd-user then neither xterm nor gnome-terminal have any groups.. so it seems generally loading   as a session module is the step causing this behavior.\\nHave not  ged how/why it causes the behaviour.\\nAlso happens when installing from git\\n',\n",
       " \"\\nI've  ged this in detail and it boils down to the call to   when dropping/restoring privileges:\\n\\n\\n\\n /security/privileges.go\\n\\n\\n        Lines 100 to 102\\n      in\\n      3e32282\\n\\n\\n\\n\\n\\n\\n if err := setGroups(target); err != nil { \\n\\n\\n\\n return err \\n\\n\\n\\n } \\n\\n\\n\\n\\nWith this commented out, the user groups are correct after login. Otherwise the user is only in the root group.\\nLooking at the source code of   (comes from util-linux on ArchLinux), there is an indication why changing the groups causes this issue: https://git.kernel.org/pub/scm/utils/util-linux/util-linux.git/tree/login-utils/login.c?h=v2.32#n1251\\nUnlike UID and GID, the supplementary group list of the target user is applied before the PAM modules are called. fscrypt breaks this by applying the supplementary groups of the root user when restoring the privileges.\\nThere are a few ways to fix this but I'm not sure which one is the best solution:\\n\\n\\nIs changing the supplementary group list even necessary? The groups of the target user are already set, so dropping and restoring the original privileges would always apply the same groups. However, I'm not sure if we can always rely on having the right groups already set. (e.g. when not using   from util-linux?)\\n\\n\\nStore the original supplementary group list by calling   before dropping privileges. That way, fscrypt could always restore them correctly.\\n\\n\\n\",\n",
       " '\\nAdditional note: I haven\\'t checked this in detail, but it seems like Ubuntu might be using   from the \"shadow\" package while Arch Linux uses the one from \"util-linux\". Unlike util-linux (as far as I can see from looking at the shadow source code), shadow sets up the groups after opening the session. This might be why this issue only happens on some distributions (those using   from util-linux):\\nSee: https://github.com/shadow-maint/shadow/blob/164dcfe65b7e81ce908121711754497c6f05a4f3/src/login.c#L868-L901\\nConsidering we can\\'t rely on having the groups already correct, solution 2 is probably the more reliable one.\\n',\n",
       " \"\\n@Minecrell thank you so much for reporting this, and it's my bad for missing the security implications of this bug. The fix in #103 is similar to your proposed solution 2.\\nThanks for the great work in finding this issue.\\n\",\n",
       " '\\n          Hitting Ctrl-C during   prompt causes a segmentation fault\\n          #78\\n',\n",
       " '\\n          PAM login failure after update to bd2ca31\\n          #93\\n',\n",
       " '\\n          Passphrase is not updated when changing   with passwd\\n          #94\\n',\n",
       " '\\n          Implement automatic unlocking though a systemd service\\n          #95\\n',\n",
       " '\\n          Cleanup privilege dropping/raising in  \\n          #103\\n',\n",
       " \"\\nI've added   to   (on Arch Linux) as described in the README:\\n \\nWith   enabled, I'm no longer in the   group after login for some reason, which means  I can no longer use  . Instead, it adds me to the root group:\\n \\nWith   commented out:\\n \\nLog:\\n \\nAny ideas? :)\\n\",\n",
       " '\\nAdd   to   instead. Auth module at bottom and session module  just below  :\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth      optional   .so\\n\\nsession    optional   pam_loginuid.so\\nsession    optional   pam_keyinit.so       force revoke\\nsession   optional   .so  drop_caches lock_policies\\nsession    include    system-auth\\n...\\n\\n',\n",
       " \"\\n@fancytenseletters Hmm, I just tried that but it doesn't make any difference unfortunately :( Same thing is still happening.\\nI removed it from   and changed   to:\\n#%PAM-1.0\\n\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth       optional    .so\\n\\naccount    required   pam_access.so\\naccount    required   pam_nologin.so\\naccount    include    system-auth\\n\\n    include    system-auth\\n\\nsession    optional   pam_loginuid.so\\nsession    optional    .so       force revoke\\nsession    optional    .so       drop_caches lock_policies\\nsession    include    system-auth\\nsession    optional   pam_motd.so          motd=/etc/motd\\nsession    optional   pam_mail.so          dir=/var/spool/mail standard quiet\\n#-session   optional    \\nsession    required   pam_env.so\\n\\n\",\n",
       " '\\n@Minecrell can you try uncommenting   and adding bypass for it (I assume you use systemd):\\n#%PAM-1.0\\n\\nauth       required   pam_tally.so         onerr=succeed file=/var/log/faillog\\nauth       required   pam_shells.so\\nauth       requisite  pam_nologin.so\\nauth       include     \\nauth       optional    .so\\n\\naccount    required   pam_access.so\\naccount    required   pam_nologin.so\\naccount    include    system-auth\\n\\n    include    system-auth\\n\\nsession    optional   pam_loginuid.so\\nsession    optional    .so       force revoke\\nsession [success=1 default=ignore]     service = systemd-user quiet\\nsession    optional    .so       drop_caches lock_policies\\nsession    include    system-auth\\nsession    optional   pam_motd.so          motd=/etc/motd\\nsession    optional   pam_mail.so          dir=/var/spool/mail standard quiet\\n-session   optional    \\nsession    required   pam_env.so\\n\\n',\n",
       " '\\n@fancytenseletters Yeah, I disabled   because it was causing   to be called twice for some reason, but it seems like your bypass using   fixes that too :) Thanks!\\nI copied your config as-is to  , but the problem persists: the user is still in the root group instead of   with  .so enabled.\\n',\n",
       " '\\nPerhaps there is some bug in  .\\nCould you post your     and log from login again?\\nAlso, can you try to create and encrypt some folder and try to relogin? How do you login? Console/sddm/lightdm/gdm?\\n',\n",
       " \"\\n@fancytenseletters Sure, I appreciate your help! :)\\nNormally I use lightdm, but for testing I have disabled it and just login from the default console login prompt. For some reason, login in lightdm is entirely broken with  . It seems to start logging in (screen turns black), but shortly after the login mask of lightdm appears again.\\nI've posted the files and logs (for console login and lightdm login) at https://gist.github.com/Minecrell/33fea177022b36313d357a3c5994b9d9\\nThe folder I created is unlocked correctly, but with console login the group is wrong and with lightdm it doesn't even log in properly.\\n\",\n",
       " '\\nDo you have https://www.archlinux.org/packages/extra/x86_64/accountsservice/ package installed?\\n',\n",
       " \"\\nI did not, but I just installed it and it doesn't make any difference either :(\\n\",\n",
       " '\\nI just realized I am also experiencing this bug. In my case, my user is not in the   group, preventing me from using USB devices in VirtualBox. I am also on Arch and using systemd (as default on Arch).\\n',\n",
       " '\\nShould we keep the  .so in   file for the   directive and move the other two to  ?\\nEDIT: I can confirm doing this change appears to fix the groups issue for me as well.\\n',\n",
       " '\\n@Minecrell can you confirm that adding     module to   fixes your issue?  Example below:\\npassword  required  pam_unix.so     try_first_pass sha512 shadow\\npassword  optional   .so\\npassword  optional  pam_permit.so\\n\\n',\n",
       " \"\\nDoesn't seem to make any difference for me :( I still get:\\n \\n... with these configs & logs: https://gist.github.com/Minecrell/53e478dc8495c93357a6bf38449fff39\\n\",\n",
       " '\\n@Minecrell I just compared your config files with mine and they look identical except for the   directive in one of the   entries. Sorry I cannot be of more help.\\n',\n",
       " \"\\nAs I was looking into reproducing #93 I managed to reproduce this bug. Here's a QEMU VM that triggers the bug running HEAD:\\nhttps://drive.google.com/open?id=1soLFKOoFHK47d31RCn6qmJB7AORe2ysg\\nUncompress (using xz, no tarball) and launch using virt-manager. Fedora 26 settings. Two users: root and qemu, both have the same  : qemu. User qemu's home is encrypted, PAM unlocking is setup.\\n\",\n",
       " '\\n@sebadoom, this is great, will investigate tonight.\\n',\n",
       " '\\nFor me, the simple change that makes this happen was when I added   to \"/etc/pam.d/systemd-user\" on my Ubuntu 18.04 (Bionic) system.\\nCurrently, the Ubuntu package does not run   for /etc/pam.d/common-session-noninteractive which is what systemd-user uses.  I was guessing this also means most of the background daemons on login don\\'t have access to the filesystem.\\nIn my attempt to resolve this I added pam.d to /etc/pam.d/systemd-user - whether I put it before or after systemd the login groups are messed up, and the session/user keys don\\'t end up linked.\\nMy understanding of PAM is really lacking at this point to understand that more.. it sounds like this is going to get replaced by systemd integration never the less thought I\\'d add the comment.\\n',\n",
       " '\\nI\\'ve realised part of the issue for me.. gnome-terminal is not actually running as a new process but is instead powered by \\'gnome-terminal-server\\' which runs under the systemd-user session .. so gnome-terminal itself and all commands you run inside of it are \"broken\" much like other services started by systemd-user in many configurations.\\n',\n",
       " '\\nI can reproduce this on a fresh Ubuntu 18.04 installation.  It happens for any PAM context where   is loaded (even if no filesystems are in use)\\n(1) Install 18.04 using http://cdimage.ubuntu.com/daily-live/current/bionic-desktop-amd64.iso\\n(2) apt-get install libpam-  fscrypt xterm\\n(3) Reboot (no need to do any fscrypt setup)\\n(4) Login, launch xterm, run \"id\" (no groups); compare to the output from \"Terminal\" (has groups); xterm (and anything else launched from gnome-shell) runs under the session scope but gnome-terminal runs under the user scope due to using gnome-terminal-server as a backend process.  Same issue occurs for anything launched from gnome-shell that requires a group, e.g. virt-manager, etc.. gnome-terminal is special because it\\'s really using a process under the systemd-user scope.  By default on Ubuntu, /etc/pam.d/systemd-user has neither   nor   (the latter is a bug, systemd upstream added it in 2016).\\n(5) If you then add   (for session) into /etc/pam.d/systemd-user then neither xterm nor gnome-terminal have any groups.. so it seems generally loading   as a session module is the step causing this behavior.\\nHave not  ged how/why it causes the behaviour.\\nAlso happens when installing from git\\n',\n",
       " \"\\nI've  ged this in detail and it boils down to the call to   when dropping/restoring privileges:\\n\\n\\n\\n /security/privileges.go\\n\\n\\n        Lines 100 to 102\\n      in\\n      3e32282\\n\\n\\n\\n\\n\\n\\n if err := setGroups(target); err != nil { \\n\\n\\n\\n return err \\n\\n\\n\\n } \\n\\n\\n\\n\\nWith this commented out, the user groups are correct after login. Otherwise the user is only in the root group.\\nLooking at the source code of   (comes from util-linux on ArchLinux), there is an indication why changing the groups causes this issue: https://git.kernel.org/pub/scm/utils/util-linux/util-linux.git/tree/login-utils/login.c?h=v2.32#n1251\\nUnlike UID and GID, the supplementary group list of the target user is applied before the PAM modules are called. fscrypt breaks this by applying the supplementary groups of the root user when restoring the privileges.\\nThere are a few ways to fix this but I'm not sure which one is the best solution:\\n\\n\\nIs changing the supplementary group list even necessary? The groups of the target user are already set, so dropping and restoring the original privileges would always apply the same groups. However, I'm not sure if we can always rely on having the right groups already set. (e.g. when not using   from util-linux?)\\n\\n\\nStore the original supplementary group list by calling   before dropping privileges. That way, fscrypt could always restore them correctly.\\n\\n\\n\",\n",
       " '\\nAdditional note: I haven\\'t checked this in detail, but it seems like Ubuntu might be using   from the \"shadow\" package while Arch Linux uses the one from \"util-linux\". Unlike util-linux (as far as I can see from looking at the shadow source code), shadow sets up the groups after opening the session. This might be why this issue only happens on some distributions (those using   from util-linux):\\nSee: https://github.com/shadow-maint/shadow/blob/164dcfe65b7e81ce908121711754497c6f05a4f3/src/login.c#L868-L901\\nConsidering we can\\'t rely on having the groups already correct, solution 2 is probably the more reliable one.\\n',\n",
       " \"\\n@Minecrell thank you so much for reporting this, and it's my bad for missing the security implications of this bug. The fix in #103 is similar to your proposed solution 2.\\nThanks for the great work in finding this issue.\\n\",\n",
       " '\\n          Hitting Ctrl-C during   prompt causes a segmentation fault\\n          #78\\n',\n",
       " '\\n          PAM login failure after update to bd2ca31\\n          #93\\n',\n",
       " '\\n          Passphrase is not updated when changing   with passwd\\n          #94\\n',\n",
       " '\\n          Implement automatic unlocking though a systemd service\\n          #95\\n',\n",
       " '\\n          Cleanup privilege dropping/raising in  \\n          #103\\n',\n",
       " '\\nFix #5364\\n',\n",
       " '\\nThank you!\\n',\n",
       " '\\n          Insecure function `isValidRedirect` leads to open redirect vulnerability \\n          #5364\\n',\n",
       " \"\\n\\nGogs version (or commit ref): <= 0.11.53.0603\\nCan you reproduce the bug at https: try.gogs.io:\\n\\n Yes (provide example URL)\\n No\\n Not relevant\\n\\n\\n\\nDescription\\nThe function   in   is used in login action to validate if url is on the same site.\\n \\nIf the   header startswith  , it will be transformed to // by browsers.\\nCheck PoC here.\\nPoC gif:\\n\\nA positive fix might looks like:\\n \\nDiscoverer: bluecatli from Tencent's Xuanwu Lab\\n\",\n",
       " '\\nThis is claimed to be fixed by merging #5365, please help test on   branch.\\n',\n",
       " '\\n          Fix open redirect vulnerability #5364\\n          #5365\\n',\n",
       " '\\nDescription\\nThis commit fixes a DoS vulnerability for certain APIs using\\nsignature V4 by verifying the content-md5 and/or content-sha56 of\\nthe request body in a streaming mode.\\nThe issue was caused by reading the entire body of the request into\\nmemory to verify the content-md5 or content-sha56 checksum if present.\\nThe vulnerability could be exploited by either replaying a V4 request\\n(in the 15 min time frame) or sending a V4 presigned request with a\\nlarge body.\\nMotivation and Context\\nSecurity, DoS\\nHow Has This Been Tested?\\nmanually\\nTypes of changes\\n\\n Bug fix (non-breaking change which fixes an issue)\\n New feature (non-breaking change which adds functionality)\\n Breaking change (fix or feature that would cause existing functionality to change)\\n\\nChecklist:\\n\\n My code follows the code style of this project.\\n My change requires a change to the documentation.\\n I have updated the documentation accordingly.\\n I have added unit tests to cover my changes.\\n I have added/updated functional tests in  . (If yes, add mint PR # here: )\\n All new and existing tests passed.\\n\\n',\n",
       " '\\nFix looks good, though not sure why the build choked.\\n',\n",
       " '\\n@donatello\\n\"Bug\" in  :\\nMissing\\n \\nWe limited the size of the request to 0...\\nFixed it.\\n',\n",
       " '\\nCodecov Report\\n\\nMerging #5957 into master will decrease coverage by  .\\nThe diff coverage is  .\\n\\n\\n \\n\\n\\n\\nImpacted Files\\nCoverage Δ\\n\\n\\n\\n\\n\\npkg/hash/reader.go\\n \\n⬆️\\n\\n\\ncmd/auth-handler.go\\n \\n⬆️\\n\\n\\ncmd/xl-v1-common.go\\n \\n⬇️\\n\\n\\ncmd/xl-sets.go\\n \\n⬇️\\n\\n\\nContinue to review full report at Codecov.\\n\\nLegend - Click here to learn more\\n ,  ,  \\nPowered by Codecov. Last update 1cf381f...b683f00. Read the comment docs.\\n\\n',\n",
       " '\\n\\nNo description provided.\\n\\n',\n",
       " '\\n@gabemontero ptal\\n',\n",
       " '\\n/lgtm\\n',\n",
       " \"\\nPerhaps unit tests to cover this are possible, but I'm good if you or somebody else does that as a follow up (assuming this needs to get merged before you head out of town).\\n\",\n",
       " '\\n[merge]\\n',\n",
       " '\\nEvaluated for source to image merge up to f5cbcbc\\n',\n",
       " '\\nSource To Image Merge Results: SUCCESS (https://ci.openshift.redhat.com/jenkins/job/test_pr_s2i/687/) (Base Commit: 2a50fd3) (PR Branch Commit: f5cbcbc)\\n',\n",
       " '\\n          [3.9] prevent save-artifact tar extraction from overwriting files out…\\n          #886\\n',\n",
       " '\\n          [3.7] prevent save-artifact tar extraction from overwriting files out…\\n          #887\\n',\n",
       " '\\nThere was a length check missing.\\n',\n",
       " '\\nCLA checker is down, feel free to merge wen if it comes back\\n',\n",
       " '\\n          Cherry-pick #5457 to 5.6: Fix missing length check in PgSQL\\n          #5472\\n',\n",
       " '\\n          Cherry-pick #5457 to 6.0: Fix missing length check in PgSQL\\n          #5473\\n',\n",
       " '\\n          Cherry-pick #5457 to 5.6: Fix missing length check in PgSQL\\n          #5478\\n',\n",
       " '\\n          Cherry-pick #5457 to 6.0: Fix missing length check in PgSQL\\n          #5479\\n',\n",
       " '\\n          Cherry-pick #5457 to 5.6: Fix missing length check in PgSQL\\n          #5480\\n',\n",
       " '\\nIssue\\nWhen using gorouter to terminate TLS we depend on gorouter to add the X-Forwarded-Proto header as either \"http\" or \"https\" depending on the protocol used to reach the router.  This is working correctly, but if X-Forwarded-Proto is already set, gorouter does nothing and allows the provided value to pass through.  This allows the client to spoof the X-Forwarded-Proto header by providing a value of \"https\" even if HTTP was used, potentially exposing traffic that should be secure and enabling MITM attacks.\\nContext\\nThere are two typical use cases for gorouter:\\n\\nOffload TLS termination outside of gorouter - in this case, the offload device needs to set the header and gorouter needs to operate as it does now (not modify the value)\\nTerminate TLS at gorouter - in this scenario you\\'d typically run a simple load balancer in front of the routers and simply pass through the connection\\n\\nIn the second scenario, gorouter is subject to header spoofing unless the load balancer is configured to strip any X-Forwarded-Proto headers before the traffic is passed to the router, but this also leaves gorouter open to spoofing if the client can connect directly to gorouter.\\nSteps to Reproduce\\n\\nConfigure gorouter to terminate TLS connections\\nHit any application expecting secure traffic via HTTP and specify the X-Forwarded-Proto header in the request, such as:\\n\\ncurl -H \"X-Forwarded-Proto: https\" http://app.exampledomain.com/\\nExpected result\\nThe request should be blocked by an app expecting secure traffic because HTTP was used.\\nCurrent result\\nThe app allows the request because the X-Forwarded-Proto header has been spoofed.\\nPossible Fix\\nA new option should be created to force gorouter to strip any provided value for X-Forwarded-Proto and add new values based on the protocol used.  This would result in three modes of operation:\\n\\nCurrent default behavior - use the value provided or add based on protocol (for TLS offload scenarios)\\nCurrent optional behavior - force to always add \"https\" when force_forwarded_proto_https is enabled (for current scenarios where this option is needed)\\nNew optional behavior - always add \"http\" or \"https\" depending on the protocol regardless of what value was provided (for scenarios where offload is not being used)\\n\\n',\n",
       " '\\nWe have created an issue in Pivotal Tracker to manage this:\\nhttps://www.pivotaltracker.com/story/show/153223820\\nThe labels on this github issue will be updated when the story is started.\\n',\n",
       " '\\nThe requested behaviors could be accomplished with the addition of a new property   which, when enabled, will cause gorouter to strip the proto header from client requests and set the header in requests to the backend based on whether the client request was http or https. Please let us know if the following interactions sound right.\\n\\nCurrent default behavior - use the value provided or add based on protocol (for TLS offload scenarios)\\n\\n \\n\\nCurrent optional behavior - force to always add \"https\" when force_forwarded_proto_https is enabled (for current scenarios where this option is needed)\\n\\n \\n\\nNew optional behavior - always add \"http\" or \"https\" depending on the protocol regardless of what value was provided (for scenarios where offload is not being used)\\n\\n \\n',\n",
       " \"\\nYes, that will work perfectly.\\nFor reference, this became an issue after transitioning to gorouter for TLS termination instead of HAProxy.  When we used to use HAProxy for termination, it was configured to strip the header before re-adding it, so this wasn't a problem.  After removing HAProxy, gorouter is subject to spoofing.\\n\",\n",
       " '\\nAny ETA on getting this implemented?\\n',\n",
       " \"\\n@amhuber - thanks for pinging. We don't have an ETA on this yet, but I am going to prioritize it to the top of our backlog and keep you updated when this is in development and when it is released.\\n\",\n",
       " \"\\nAccording to the user story it looks like this is held up due to some interaction with routing services.  Once again, given the security implications of this enabling MITM attacks, I'm concerns that this isn't being addressed more urgently.  Any update on getting this fix added into the release?\\n\",\n",
       " '\\n@amhuber - we are still planning to work on this and it is currently top of our backlog. We wanted to tackle all issues that are impacted by route services in a way that is comprehensive and design a solution that works across usecases for route services. We now have a way forward there. That said, fixed a security vulnerability that had higher priority than this issue in the last few weeks and is focussed on using Istio /Pilot and Envoy in the routing control plane which has slowed our progress on this. This issue is now at the top of the backlog, and a pair should pick it up soon. I agree that the security vulnerability makes this important to address asap.\\n',\n",
       " '\\nI have picked up this work.  We will keep this issue updated as we make progress.\\n',\n",
       " '\\nAwesome, thanks for the update.\\n',\n",
       " \"\\nI'm sorry to say that we've set this back down, as PMs have prioritized other work above it.\\ncc @shalako and @shubhaat\\n\",\n",
       " '\\n@amhuber This has been fixed with routing-release 0.175.0.\\n',\n",
       " '\\n@shubhaat Can we close it now?\\n',\n",
       " '\\n@rosenhouse - Sure.\\n@amhuber - please feel free to let us know when you have had a chance to try it.\\n',\n",
       " \"\\nThanks, I took a quick look at the commits and everything looks good to me.  We'll test this out ASAP but no issue closing the request.  Thanks for getting this in place.\\n\",\n",
       " '\\nThis issue has been assigned CVE-2018-1193 - https://www.cloudfoundry.org/blog/cve-2018-1193/\\n',\n",
       " '\\n          Route services cannot determine if original request via TLS\\n          #170\\n',\n",
       " '\\nWhy this PR?\\nThis PR is meant to fix an arbitrary file write vulnerability, that can be achieved using a specially crafted zip archive, that holds path traversal filenames. When the filename gets concatenated to the target extraction directory, the final path ends up outside of the target folder.\\nA sample malicious zip file named  . (see this gist) was used, and when running the code below, resulted in creation of   file in /tmp folder.\\n \\nThere are various possible ways to avoid this issue, some include checking for   (dot dot) characters in the filename, but the best solution in our opinion is to check if the final target filename, starts with the target folder (after both are resolved to their absolute path).\\nStay secure,\\nSnyk Team\\n',\n",
       " \"\\nI'll add a test next week, but if you can't wait, the idea is to extract the   malicious zip file, and make sure a file /tmp/  was not created. I'm not sure how to do it in a way that would work for windows et. al.\\n\",\n",
       " \"\\nExcellent. I'm not too picky about that name, I think it's good. Thank you for contributing this!\\nA test would definitely be good to have, so if you have the time, I think that'd be important. Thanks ;)\\n\",\n",
       " \"\\nThe fix is insufficient because you can use symlinks in   files to get around it.\\nThe following PoC creates a symlink   and then tars it with a file that is referenced through that symlink. Upon unpacking it will first unpack the symlink, which will now point to the root filesystem, and then the second file can use it to write anywhere.\\n \\nI'm not sure what a good fix would be, as symlinks are a feature of   files. And it could break existing projects that rely on symlinks. Maybe a flag to enable symlinks would make sense, and have it off by default?\\nPS: Symlinks are theoretically also supported by   files, but archiver doesn't implement it (actually many zip libraries don't support them). So in case this support would be added in the future, this has to be considered as well.\\nedit: sorry, just noticed that there is already an open issue about that #69\\n\",\n",
       " \"\\n@mholt if you need snyk's help with this - we're happy to chip in :D\\n\",\n",
       " '\\nI would love some help. Been too busy to maintain this lately. Would anyone be able to commit a little time to improve this lib? I will make you a collaborator. :)\\n',\n",
       " '\\ncould you please review #70 ?\\n',\n",
       " '\\nCan you confirm this fix is in golang 10.3?\\n',\n",
       " '\\ncancel that, this is a separate project\\n',\n",
       " '\\nHow this work with following files?\\ndestination = \"/foo/bar\"\\nextracted file = \"/foo/bar/ /../../../etc/hosts\"\\nI don\\'t make sure but you have to call filepath.Clean() before checking.\\n',\n",
       " \"\\n@mattn the fix for the issue you're describing has already been merged - this is what this PR solved.\\n\",\n",
       " '\\n@aviadatsnyk do you mean this PR solve my comment?\\nhttps://github.com/mholt/archiver/pull/65/files\\n \\nThis condition possibly pass insecure paths.\\ndestination = \"/foo/bar\"\\nextracted file = \"/foo/bar/ /../../../etc/hosts\"\\n',\n",
       " '\\nthat is what I meant.\\nsee https://play.golang.org/p/9R8ozZaC80X\\n',\n",
       " '\\nAh, I missed it.\\n',\n",
       " '\\n          Bug 1466872: Fix zip slip vulnerability\\n          #99\\n',\n",
       " '\\n          fix: #65#issuecomment-395988244 - zip slip by symlink\\n          #70\\n',\n",
       " '\\n          archive/zip: sanitize the FileHeader.Name to remove path traversal (\" /../\") from zip files?\\n          #25849\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nAfter explaining the issue in private with the security mailing list, we determined it is low enough in severity to make it a public discussion.\\nThis issue is relevant only to etcd deployment on local networks with no authentication scheme set up. It may not be a common scenario but it affects anyone who work with etcd locally or on a local network and use it without authentication, which is the default. For the sake of demonstration, I'm using a scenario where etcd is deployed on localhost. This can be any LAN address though (the attacker would have to know the address as a perquisite, but localhost is pretty common).\\nThe first issue is with CSRF. An attacker can set up a website that tries to send a POST request to the etcd server and modify a key. Adding a key is done with PUT so it is theoretically safe (can't PUT from an HTML form or such) but POST allows creating in-order keys that an attacker can send.\\nExample PoC:\\n \\nThe second issue is with DNS rebinding. It essentially means an attacker can control his DNS records to direct to localhost, and trick the browser into sending requests to localhost (or any other address).\\nThere are many resources on how this attack works.\\nI've set up a live PoC at 35.205.198.70 (based on taviso's work). If the issue is unclear though please let me know and I will explain the attack in further details.\\nSuccess example:\\n\\nWhitelisting hostnames is a possible simple solution. See taviso's comment on this or the fix he sent to Transmission.\\n\",\n",
       " \"\\nWe've added   flag. This will be released in 3.4.\\nThanks for report!\\n\",\n",
       " '\\nany cve assigned to these issues ?\\n',\n",
       " \"\\n@sidhax I've attempted to assign CVE IDs through DWF but CoreOS is acquired by Red Hat so it was\\nforwarded to them and I wasn't yet informed of anything from their side\\n\",\n",
       " '\\nTwo CVEs were assigned for this:\\nCVE-2018-1098 etcd: Cross-site request forgery via crafted local POST forms\\nCVE-2018-1099 etcd: DNS rebinding vulnerability in etcd server\\n',\n",
       " '\\nThanks @pedrohc\\n',\n",
       " '\\n          *: fix Makefile, move GOPATH setup to build script\\n          #9370\\n',\n",
       " '\\n          CHANGELOG: add changes for next patch release\\n          #9341\\n',\n",
       " '\\n          *: mitigate DNS rebinding attacks in insecure etcd server\\n          #9372\\n',\n",
       " \"\\nWhen getting service logs, if a snap name is given but it has no\\nservices, a 404 is returned. However if no names were given we would\\ncall journalctl with no match arguments (because ∀ is true on the\\nempty set), meaning we'd ship all the logs out. This fixes that.\\n\",\n",
       " '\\nCodecov Report\\n\\nMerging #4194 into master will decrease coverage by  .\\nThe diff coverage is  .\\n\\n\\n \\n\\n\\n\\nImpacted Files\\nCoverage Δ\\n\\n\\n\\n\\n\\ndaemon/api.go\\n \\n⬆️\\n\\n\\nhttputil/useragent.go\\n \\n⬇️\\n\\n\\ncmd/snap-seccomp/main.go\\n \\n⬇️\\n\\n\\ninterfaces/sorting.go\\n \\n⬇️\\n\\n\\noverlord/ifacestate/helpers.go\\n \\n⬇️\\n\\n\\nhttputil/redirect18.go\\n\\n\\n\\n\\nhttputil/transport17.go\\n\\n\\n\\n\\ncmd/snap-update-ns/entry.go\\n \\n⬆️\\n\\n\\ninterfaces/mount/entry.go\\n \\n⬆️\\n\\n\\nContinue to review full report at Codecov.\\n\\nLegend - Click here to learn more\\n ,  ,  \\nPowered by Codecov. Last update 15565f3...edb2d25. Read the comment docs.\\n\\n',\n",
       " '\\nserveTCP calls reader.ReadTCP in the accept loop rather than in\\nthe per-connection goroutine. If an attacker opens a connection\\nand leaves it idle, this will block the accept loop until the\\nconnection times out (2s by default). During this time no other\\nincoming connections will succeed, preventing legitimate queries\\nfrom being answered.\\nThis commit moves the call to reader.ReadTCP into the per-connection\\ngoroutine. It also adds a missing call to Close whose absence allowed\\nfile-descirptors to leak in select cases.\\nThis attack and fix have no impact on serving UDP queries.\\n',\n",
       " '\\nFixes #631\\n',\n",
       " '\\nCodecov Report\\n\\nMerging #631 into master will decrease coverage by  .\\nThe diff coverage is  .\\n\\n\\n \\n\\n\\n\\nImpacted Files\\nCoverage Δ\\n\\n\\n\\n\\n\\nserver.go\\n \\n⬇️\\n\\n\\nContinue to review full report at Codecov.\\n\\nLegend - Click here to learn more\\n ,  ,  \\nPowered by Codecov. Last update 862243b...ee6a9d6. Read the comment docs.\\n\\n',\n",
       " '\\n          CVE-2017-15133\\n          #627\\n',\n",
       " '\\n          Update vendored DNS lib\\n          #3859\\n',\n",
       " '\\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=2017-15133\\n',\n",
       " '\\nNote this is under embargo and a number of projects and companies have been privately contacted so they can update their infrastructure.\\n',\n",
       " '\\nWe tentatively planning to release 1.0.4 of this library with the mitigation applied at the end of this month.\\n',\n",
       " '\\nclosed via #631\\n',\n",
       " '\\n          CoreDNS 1.0.4\\n          #1397\\n',\n",
       " '\\n          Upgrading to CoreDNS 1.0.4 \\n          apprenda/kismatic#1061\\n',\n",
       " '\\n          Upgrading to CoreDNS 1.0.4\\n          apprenda/kismatic#1063\\n',\n",
       " '\\n          Update miekg/dns for CVE-2017-15133\\n          #3223\\n',\n",
       " '\\n          Update miekg/dns for CVE-2017-15133\\n          #3835\\n',\n",
       " '\\n          Update miekg/dns for CVE-2017-15133\\n          #25\\n',\n",
       " \"\\nthe codebase had this comment:\\n \\nRight now we're cutting a lot of corners and doing things not securely yet. But it's important to flag them as such for people who might be just browsing the codebase. If I saw that on a random codebase i'd be alarmed, even knowing the code is changing.\\n\",\n",
       " '\\n+💯\\n\\nleaving explicit TODOs and FIXMEs\\n\\n',\n",
       " '\\nwoops..... +1\\n',\n",
       " \"\\nthe codebase had this comment:\\n \\nRight now we're cutting a lot of corners and doing things not securely yet. But it's important to flag them as such for people who might be just browsing the codebase. If I saw that on a random codebase i'd be alarmed, even knowing the code is changing.\\n\",\n",
       " '\\n+💯\\n\\nleaving explicit TODOs and FIXMEs\\n\\n',\n",
       " '\\nwoops..... +1\\n',\n",
       " \"\\nThis can be helpful for audit logging, and generating alerts on authentication failures. If a request fails to authenticate, you'll see a log line like:\\n \\nAdditionally, it extends the   log line with some additional fields that can be useful for debugging/auditing (user agent, remote ip):\\n \\n\",\n",
       " '\\nThis is normally used for unauthenticated bind, and\\nhttps://tools.ietf.org/html/rfc4513#section-5.1.2 recommends:\\n\\nClients SHOULD disallow an empty password input to a Name/Password\\nAuthentication user interface\\n\\n',\n",
       " \"\\n\\nI think this is just a matter of a new version tag?\\n\\nDefinitely a new version tag. I'd like it to be a major version, but there were other breaking changes I wanted to see in the 3.0 bump that I don't have bandwidth to do in the next few days. I'm ok merging this into master, starting a v2 maintenance branch just prior to this, and holding tagging a 3.0 release until the other cleanup tasks are done\\n\",\n",
       " \"\\nI'll merge to master and open a new v2 maintenance branch just prior to this merge.\\n\",\n",
       " '\\n          Fix control packets being encoded when none exist on bind\\n          #142\\n',\n",
       " '\\n\\nNo description provided.\\n\\n',\n",
       " '\\n\\nCoverage remained the same at 74.257% when pulling eddce24 on polezaivsani:fix_timming_sidechannel into 2eb16e9 on robbert229:master.\\n',\n",
       " '\\nThanks for the pr!\\n',\n",
       " '\\n          Secure problem\\n          #12\\n',\n",
       " '\\nAs described here, please change your comparation to default buildin function when hmac is used\\nWith gratitude,\\nVetcher\\n',\n",
       " '\\nThanks! I am currently super busy and unable to update this myself. I am open to a PR though!\\n',\n",
       " '\\nClosed in #13\\n',\n",
       " '\\nI am trying to create a simple example of a REST server with JWT authentication. Everything works fine except for the validateTokenMiddleware function, which keeps giving the message \"Key is of invalid type\".\\nThe original example was based on version 2 of jwt-go. I have amended what I believe that should be amended for version 3. However, regarding the error I\\'m receiving it\\'s unclear whether I made a mistake or if there is a bug in the jwt-go package here. I for sure don\\'t see a reason why I\\'m getting this error.\\n \\n',\n",
       " \"\\nThe RSA SigningMethod no longer accepts a slice of bytes.  You must provide an rsa.PublicKey for validation.  There are helper methods provided for parsing PKCS keys.\\nThe implementation used to do this under the hood for common formats, but that presents a vulnerability when it's used incorrectly.  By requiring the correct type of key, there is more protection built in.\\n\",\n",
       " \"\\nTo you of the future who may be me, the droid you're looking for might reside here: https://golang.org/pkg/crypto/x509/#ParsePKCS1PublicKey\\nGodspeed.\\n\",\n",
       " \"\\nThe README still says this:\\n\\nNOTICE: A vulnerability in JWT was recently published. As this library doesn't force users to validate the alg is what they expected, it's possible your usage is effected. There will be an update soon to remedy this, and it will likey require backwards-incompatible changes to the API. In the short term, please make sure your implementation verifies the alg is what you expect.\\n\\nThis vulnerability was published in 2015. If it has been addressed in go-jwt then maybe the notice should be removed?\\n\",\n",
       " '\\nI believe this refers to the   verification algorithm that is weirdly present in the JWT standard. This library still does not force the user to validate the alg sent in the token, and there is documentation encouraging users to do this. Additionally the   algorithm has been disabled default in this library here. It appears to be addressed, however I am no cryptographer. I would also appreciate clarity from the maintainer(s).\\n',\n",
       " \"\\nI've updated the note as it's still worth mentioning.  As of 3.0.0, key types are not compatible across signing methods, which really helps.  It's still possible to get this wrong, so it's worth keeping a mention of it up front.\\nThis satisfactory to close the ticket?\\n\",\n",
       " '\\n\\nThis satisfactory to close the ticket?\\n\\nIMO, yes.\\n',\n",
       " \"\\nIt seems this binding is using the unsafe version of the decoder (LZ4_uncompress). As a consequence, a malicious user could slip-in some forged input to trigger an attack.\\nAs a way to improve security, it would be better to use the safe version instead.\\nThe safe version is called LZ4_decompress_safe().\\nIt's also recommended to update the C source to r119, which improves security for 32-bits systems.\\n\",\n",
       " \"\\nThanks. I've done both.\\nC source is now r119 and switched to LZ4_decompress_safe.\\n\",\n",
       " '\\nClientConfig.HostKeyCallback interprets nil as \"accept any host keys\". This is not a great default from a security perspective. Many clients probably should set HostKeyCallback to something real but are not.\\nIt was written this way in golang.org/cl/9922043 to preserve backwards compatibility with the original implementation, but that was probably not the right balance to strike.\\nThis issue is to make HostKeyCallback=nil mean \"reject all host keys\" and at the same time provide at least\\n \\nand maybe also\\n \\nThanks to Phil Pennock for pointing out this problem.\\n',\n",
       " '\\nsee https://go-review.googlesource.com/c/38701/\\n',\n",
       " '\\nCL https://golang.org/cl/38701 mentions this issue.\\n',\n",
       " '\\nFor reference, this is now:  \\n',\n",
       " '\\nHello,\\nThis issue not occurred on \"go1.8.1 darwin/amd64\". I think that \"go1.8.1 darwin/amd64\" and \" go1.8.1 linux/amd64\" is not same in ssh package. Can  \"go1.8.1 darwin/amd64\" commits  be behind to \" go1.8.1 linux/amd64\". It is possible @rsc\\n',\n",
       " '\\nHello again.\\nI forget do \"go get -u github.com/pkg/sftp\" with \"-u\" flag. Sorry for attention :(\\n',\n",
       " '\\nI had a question about the approach used to solve this.  I understand the reason for the breaking change, but I\\'m wondering if there is a way to implement this so that the \"break\" occurs during build as opposed to at run time.  That would lessen the impact and the surprises that come up after a build was successful and then the first run in production fails for some error that you\\'ve never seen before.\\nThoughts?\\n',\n",
       " \"\\n@CameronGo, had there been a nice solution with that property (failing at compile time instead of run time), we would've used it. But e.g. renaming renaming ssh.ClientConfig to ssh.ClientConfig2 would've been super gross.\\n\",\n",
       " '\\nUnderstood - (and agreed on the latter point for sure).\\n',\n",
       " '\\nHow can agent forwarding be supported this this case, the mux ssh server\\nclient -> mux -> remote\\n',\n",
       " '\\n          Fix examples in light of HostKeyCallback issue\\n          #177\\n',\n",
       " '\\n          Add new required SSH param HostKeyCallback\\n          #34\\n',\n",
       " '\\n          Question: Is concourse/tsa succeptible to   ?\\n          #1023\\n',\n",
       " '\\n          Fixes #177: adds HostKeyCallback to ssh.ClientConfig\\n          #179\\n',\n",
       " '\\n          x/crypto/ssh: Failed to open ssh connection to the server: ssh: must specify HostKeyCallback\\n          #20200\\n',\n",
       " '\\n          Any remote operation where ssh is involved fails on the latest version of x/crypto/ssh\\n          #379\\n',\n",
       " '\\n          Cannot clone using private key\\n          #385\\n',\n",
       " \"\\n          FIXED: 'must specify HostKeyCallback' \\n          #28\\n\",\n",
       " '\\n          [check-ssh] fix the problem that check-ssh cannot invoke SSH connection\\n          #171\\n',\n",
       " '\\n          Add HostKeyCallback\\n          #1\\n',\n",
       " '\\n          alicloud-ecs: must specify HostKeyCallback\\n          #5001\\n',\n",
       " '\\n          crypto/ssh: Must specify HostKeyCallback\\n          #4172\\n',\n",
       " '\\n          Fails to start on Go 1.8.3, HostKeyCallback required\\n          #2\\n',\n",
       " '\\n          fix `ssh: must specify HostKeyCallback`\\n          #18\\n',\n",
       " '\\n          fix(ssh): set HostKeyCallback to nil\\n          #10\\n',\n",
       " '\\n          Fix ssh\\n          #16\\n',\n",
       " '\\n          Fix ssh\\n          #17\\n',\n",
       " '\\n          Cleanup imports\\n          #1\\n',\n",
       " '\\n          add default HostKeyCallback to SSH client config\\n          #29\\n',\n",
       " '\\n          Adding default on HostKeyCallback\\n          robermorales/sshmux#1\\n',\n",
       " '\\n          Adding default on HostKeyCallback\\n          kennylevinsen/sshmux#2\\n',\n",
       " '\\n          Adds HostKeyCallback to ssh.ClientConfig\\n          #4\\n',\n",
       " '\\n          fix(plugin): fix ssh-cmd config\\n          #2665\\n',\n",
       " '\\nThis implements CSRF protection for the initiation and termination of the OAuth flow. (thanks @arnottcr and @TheRook for the contribution).\\nFixes #336, #321\\n',\n",
       " \"\\n@jehiah   @arnottcr Can you help me understand specifically why this PR was submitted?\\nI'm using oauth2 proxy at   to protect a resource  .\\nRE: this specific function: 55085d9#diff-6fd8df33d9f8086bc31e28c375fbc0abL387\\nAFAICT, this code means that hitting   will never work, because the redirect is always reset to /.\\nDoes it ever make sense to relax this?\\n\",\n",
       " '\\nI may not have linked the exact right location in code, there are a couple functions that \"filter\" the redirect down to \\' \\'.\\nIt seems like this was done for security reasons. Would it be sufficient to accept a list of domains to respect? (For example, I am already having oauth2proxy set the cookie domain to mydomain.tld, can I also have a   or some such?\\n',\n",
       " '\\n          Support for a whitelist of `--redirect-domains`\\n          #399\\n',\n",
       " \"\\nA PodSecurityPolicy admission plugin vulnerability allows users to make use of any PodSecurityPolicy object, even ones they are not authorized to use.\\nCVE: CVE-2017-1000056\\n\\nFixed in v1.5.5 in 7fef0a4\\nFixed in release-1.5 branch in #43491\\nFixed in master in #43489\\n\\nWho is affected?\\nOnly Kubernetes 1.5.0-1.5.4 installations that do all of the following:\\n\\nEnable the PodSecurityPolicy API (which is not enabled by default):\\n \\nEnable the PodSecurityPolicy admission plugin (which is not enabled by default):\\n \\nUse authorization to limit users' ability to use specific PodSecurityPolicy objects\\n\\nkubeadm and GKE do not allow enabling PodSecurityPolicy in 1.5, so are not affected by this vulnerability.\\nkube-up.sh and kops do not enable PodSecurityPolicy by default, so are not affected by this vulnerability. A modified kube-up.sh or kops deployment could have enabled it.\\nWhat is the impact?\\nA user that is authorized to create pods can make use of any existing PodSecurityPolicy, even ones they are not authorized to use.\\nHow can I mitigate this prior to installing 1.5.5?\\n\\n\\nExport existing PodSecurityPolicy objects:\\n \\n\\n\\nReview and delete any PodSecurityPolicy objects you do not want all pod-creating users to be able to use (NOTE: Privileged users that were making use of those policies will also lose access to those policies). For example:\\n \\n\\n\\nAfter upgrading to 1.5.5, re-create the exported PodSecurityPolicy objects:\\n \\n\\n\\n\",\n",
       " '\\nKubeadm and GKE do not allow enabling PodSecurityPolicy in 1.5, so are not affected by this.\\nKube-up.sh and kops do not enable PodSecurityPolicy by default. A modified kube-up.sh or kops deployment could have enabled it.\\n',\n",
       " '\\n          Authorize PSP usage for pods without service accounts\\n          #43489\\n',\n",
       " \"\\nHi,\\nIn code reviewing, i found an infinite loop vulnerability in retrieving images chain using docker2aci, it occurs during the corresponding json file parsing from user's image archive, fetching the parent image ID until ID is nil. There must be a possibility that the images chain may be a closed cycle, thus , docker2aci will fall into an infinite loop, that's indeed true by some interesting tests.\\nI think the core cause of this issue is lacking in essential check for duplicated image ID, such as the current image ID could not be equal to its parent image ID, most important, check whether the images chain is a closed cycle.\\nI processed some interesting test for this issue, building a crafted image whose top layer's parent ID points to itself, then an infinite loop occurred, this flaw caused excessive CPU cycles & resources consume   on the host.\\nexpecting subsequent discuss and fix the issue together, and could you request a CVE identifier for that ?\\n\",\n",
       " \"\\nThanks for the report @TheBeeMan. From the description above, even if not explicitly stated it looks like your code review is covering the logic in getAncestry() (please pinpoint if this covers something else instead).\\nIn the above code, I agree that the current parent-handling behavior is buggy as it doesn't take into account cyclic dependencies.\\nHowever I'm not completely sure about any security implication of this. Triggering this infinite loop seems to require local access and only concern a single user process. This will just result in a never-ending conversion of a single malformed image, which shouldn't impact availability per-se as there is no single service to DoS here. As you pointed out, there will be indeed some over-usage of processing resources but this is something that is typically controlled by the OS (eg. via cgroups, priority-throttling, OOM-killing).\\nWhat's was your original impact analysis of this suggesting that it requires a CVE?\\n\",\n",
       " '\\nThis is a typical denial of service vulnerability, which could result in over-usage of processing resources. I think it is a CVE worthy vulnerability, although it is a low severity issue but a crafted image could cause docker2aci fall into a never-ending conversion.\\nThe way you think about security is different with me, denial of service is a grey area, Obviously if I send 10 gigabits of request traffic or an valid input files and the processor gets slow/non responsive the CVE response would be \"No CVE for you\" ,but if a single crafted file prevents the whole system from working in an expected manner, that may be a problem that is worth a CVE.\\nJust for reference, infinite loop is a well-known security issue (CWE-835)\\n',\n",
       " '\\nCould you request a CVE for that ?\\n',\n",
       " \"\\nSure! I've just forwarded this to CVE Assignment Team at MITRE and put you in copy. We'll be waiting for their reply regarding submission review and CVE ID allocation. Thanks again for following up on this.\\n\",\n",
       " '\\nAfter MITRE review, in the context of docker2aci usage as an embedded library, this bug has been recognized as a security issue and assigned CVE-2016-8579.\\nHere the reply from CVE Assignment Team:\\n \\n',\n",
       " '\\n@TheBeeMan a proposed fix for this is up at #204, adding additional validation on crafted images. Can you please take a look at it?\\n',\n",
       " '\\ni reviewed the patch for CVE-2016-8579 and processed some tests with the previous malicious image, it addressed the issue.\\ni agree.\\n',\n",
       " '\\n          Additional validation on malformed images\\n          #204\\n',\n",
       " \"\\nDescription\\n> in code reviewing, i found a path traversal vulnerability in docker's image converting using docker2aci, there must be a possibility that it extracts embedded layer data to arbitrary directories or paths since no essential  check for file path, RCE or privilege escalation would be performed.\\n> it is indeed true that i tested  the issue by building a malicious image, if running as root,  arbitrary file could be written into arbitrary paths, like backdoors, or running as unprivileged user,  arbitrary files also could be extracted to some paths within the capabilities of current user.\\n> It is quite critical,  right ? Could you request a CVE for that ?\\n\",\n",
       " \"\\nThanks for submitting this bug report. docker2aci development is primarily handled by CoreOS, so we'd like to handle this via our Security Disclosure policy. Could you kindly send an email to security@coreos.com with more details so we can investigate further?\\nhttps://coreos.com/security/disclosure/\\n\",\n",
       " '\\nfine\\n',\n",
       " '\\nthe issue has been sent to security@coreos.com by email, no response. I gonna report it to oss-security for handling, and request a CVE identifier, ok ?\\n',\n",
       " '\\nFor reference, this has been assigned CVE-2016-7569 with a low to medium impact, typically mitigated for remote attack vectors.\\nGiven the very short timeline for the disclosure, a patch is currently being worked on and will appear in the next release.\\n',\n",
       " '\\n@TheBeeMan a proposed fix for this is up at #204, adding additional validation on crafted images. Can you please take a look at it?\\n',\n",
       " '\\ni reviewed the patch forCVE-2016-7569 and processed some tests with the previous malicious image, it addressed the issue.\\n',\n",
       " '\\n          Additional validation on malformed images\\n          #204\\n',\n",
       " '\\noci-register-machine can be considered an information leak for\\ncertain container workloads.  It allows information about the container\\nto be viewed by non privileged users.  Some adinistrators may want to disable\\ncontainers reporting this information to systemd-machinectl.  We want this\\npackage installed by default, and removing this package is not an option\\non atomic host.\\nThis patch adds a /etc/oci-register-machine.conf which contains a json\\ndata to disable the tool.\\n',\n",
       " '\\n@mrunalp @lsm5 PTAL\\n',\n",
       " '\\nThe goal of this is to fix https://bugzilla.redhat.com/show_bug.cgi?id=1366402\\n',\n",
       " '\\nLGTM\\n\\nOn Aug 17, 2016, at 6:20 AM, Daniel J Walsh notifications@github.com wrote:\\n@mrunalp @lsm5 PTAL\\n—\\nYou are receiving this because you were mentioned.\\nReply to this email directly, view it on GitHub, or mute the thread.\\n\\n',\n",
       " \"\\n'//foo.com/foo' is a valid url, so the redirect check at oauthproxy.go:479 is not sufficient for its intent.\\nSince I'm using this hole to redirect to other domains within a set of subdomains -- it would be cool if this was somehow preserved so I can have a partially open redirect.  (I'm using an 'auth' domain and redirect to it from other domains and then redirect back while using the nginx aut -- I plan on writing up the configuration soon for others to use.)\\n\",\n",
       " '\\n@sdier can you share the config briefly?\\n',\n",
       " '\\n          Improve redirect checks\\n          #359\\n',\n",
       " '\\n          Support for a whitelist of `--redirect-domains`\\n          #399\\n',\n",
       " '\\nThe current parsing of the \"rd\" and \"state\" query parameters allow for an open redirect, if the rd values is of the form  .\\nFixes #228\\n',\n",
       " \"\\n          Default login form doesn't set rd to URL\\n          #378\\n\",\n",
       " '\\n          Support for a whitelist of `--redirect-domains`\\n          #399\\n',\n",
       " \"\\nTaru Karttunen noted that Go should be more paranoid by default when loading DLLs.\\nBackground:\\nhttps://textplain.wordpress.com/2015/12/18/dll-hijacking-just-wont-die/\\nMicrosoft's guidelines:\\nhttps://msdn.microsoft.com/en-us/library/ff919712%28VS.85%29.aspx\\n  docs:\\nhttps://msdn.microsoft.com/en-us/library/ms684179(v=vs.85).aspx\\n@rsc proposed:\\n\\n\\nChange   to call LoadLibraryEx with flags=LOAD_LIBRARY_SEARCH_SYSTEM32 instead of calling LoadLibrary. That is, LoadDLL is now secure by default and cannot load DLLs from the directory containing the executable.\\nAdd a LoadLibraryEx to  /win so that users can still get at the old behavior if they want it (by appropriate passing of flags).\\n\\n\\nCL forthcoming.\\n/cc @alexbrainman @adg @broady @jbuberel @ianlancetaylor\\n\",\n",
       " '\\n/cc @taruti, too.\\n',\n",
       " '\\nProposed fix: https://golang.org/cl/21140\\n',\n",
       " \"\\nI'm not convinced that Go needs to solve this problem because dso hijack is\\nequally easy on Unix (e.g. via LD_PRELOAD) and yet we don't protect from it\\n(I actually think it's a feature, not a bug.)\\nBesides, this is not backward compatible as we silently changed the semantics\\nof  .\\nI'm fine if we only change the runtime to load ntdll.dll, kernel32.dll, etc. with\\nLOAD_LIBRARY_SEARCH_SYSTEM32, but we should definitely preserve\\nthe existing   behavior.\\n\",\n",
       " \"\\nYour analogy isn't complete.\\nWindows users download binaries and double-click those binaries from their Downloads folder. Windows users can get (malicious) DLLs silently downloaded to their Downloads folder just by browsing the web. Windows users don't need to set LD_PRELOAD to shoot themselves in the foot. The gun is always pointed down towards the foot by default on Windows.\\n\",\n",
       " '\\nCL https://golang.org/cl/21140 mentions this issue.\\n',\n",
       " '\\nFYI, the order of paths for searching dll(s)\\nhttps://msdn.microsoft.com/en-us/library/7d83bc18.aspx\\n\\nThe directory where the executable module for the current process is located.\\nThe current directory.\\nThe Windows system directory. The GetSystemDirectory function retrieves the path of this directory.\\nThe Windows directory. The GetWindowsDirectory function retrieves the path of this directory.\\nThe directories listed in the PATH environment variable.\\n\\n',\n",
       " '\\n\\nBackground:\\nhttps://textplain.wordpress.com/2015/12/18/dll-hijacking-just-wont-die/\\n\\nI read the article, and I don\\'t see what the problem is. I went to the page pointed by the article which is suppose to automatically download malicious DLL, but my Chrome actually refused to download the DLL. Chrome told me that DLL looks suspicious and I shouldn\\'t be downloading it.\\nAs to CL 21140, I think it breaks existing valid programs. Somehow CL assumes that   is onle used to load \"system\" DLLs. But that is not true. It is quite common to put application specific DLLs into  application directory - directory where executable is located. How do you propose we handle this scenario if CL 21140 is accepted?\\nIf you think there is something for us to fix here, perhaps we could create new syscall.LoadSystemDLL (or similar) that does what you want, and change all standard packages to use syscall.LoadSystemDLL.\\nAlex\\n',\n",
       " '\\n\\nbut my Chrome actually refused to download the DLL. Chrome told me that DLL looks suspicious and I shouldn\\'t be downloading it.\\n\\nChrome was updated according to the comments. The post also mentions the Edge browser (the default Microsoft browser) and comments suggest it hasn\\'t been updated. I haven\\'t tried.\\n\\nAs to CL 21140, I think it breaks existing valid programs.\\n\\nhttps://golang.org/doc/go1compat says \"A security issue in the specification or implementation may come to light whose resolution requires breaking compatibility. We reserve the right to address such security issues.\"\\nI believe calling   is unchanged in behavior, if people really need to use the standard library to load DLLs out of the current directory.\\n\\nIf you think there is something for us to fix here, perhaps we could create new syscall.LoadSystemDLL (or similar) that does what you want, and change all standard packages to use syscall.LoadSystemDLL.\\n\\nThe proposal is to add that not to the standard library, but to  . (See the original comment at the top of this bug).\\n',\n",
       " '\\n\\nI believe calling  (\".\\\\foo.dll\") is unchanged in behavior, if people really need to use the standard library to load DLLs out of the current directory.\\n\\nCurrent directory yes, but that is not what I was talking about. Some apps store DLLs in the directory where EXE is located. How do you propose people load these DLLs?\\nAlex\\n',\n",
       " '\\n\\nCurrent directory yes, but that is not what I was talking about. Some apps store DLLs in the directory where EXE is located. How do you propose people load these DLLs?\\n\\nSee the top comment in this bug: \"2) Add a   to  /win so that users can still get at the old behavior if they want it (by appropriate passing of flags).\"\\n(A flags of 0 would mean the current behavior)\\n',\n",
       " '\\nHere is one of many programs I use on my PC.\\n \\nJust to demonstrate that behaviour you\\'re about to break is actually used by some products.\\n\\nSee the top comment in this bug: \"2) Add a   to  /win so that users can still get at the old behavior if they want it (by appropriate passing of flags).\"\\n(A flags of 0 would mean the current behavior)\\n\\nBut that will still break my existing code. I don\\'t personally have problem like described in https://textplain.wordpress.com/2015/12/18/dll-hijacking-just-wont-die/. Why should I suffer? Why cannot we do what I suggested above? What is the downside?\\nAlex\\n',\n",
       " \"\\nI propose we add the new   function and proactively fix all known public code on Github to use the new   function instead of  .\\n@minux, @alexbrainman, I consider both of you advanced users who would use  , but I don't suspect there is much total code out there that would be affected.\\n\",\n",
       " \"\\n\\nI propose we add the new   function\\n\\nI don't think this will work for what your broke. Since you changed   (in CL 21140), you would have to provide similar alternative. In syscall package too. Otherwise people would have to change too much code if they need to import   /windows as well as syscall, and things can get messy. I don't use x/sys/windows myself, it is difficult for me to see what can go wrong here.\\nAlex\\n\",\n",
       " '\\nI checked loading dll from go.\\n \\nbuild kernel32.dll\\n \\nloader written in go\\n \\nthen, pass argument pointed path to kernel32.dll like below\\n \\n\\n\\n\\nArgument\\nResult\\n\\n\\n\\n\\nkernel32\\nOK\\n\\n\\nkernel32.dll\\nOK\\n\\n\\n./kernel32\\nEvail\\n\\n\\n./kernel32.dll\\nEvail\\n\\nproblems seem to not occur unless the program point to kernel32.dll relatively or point to kernel32.dll directly.\\n',\n",
       " '\\n@mattn, That is because Windows registry has a list of dlls that will always be loaded from a system directory first. That covers some, but not all of the dlls that are used by Go stdlib.\\nI see at least three possible solutions:\\nA) Fix LoadDll and make applications deal with it.\\nB) Have a syscall.LoadDllSafe and change stdlib to use that (or even internal/syscall/windows.LoadDllSafe) and change nothing for custom user code.\\nC) Do nothing\\n',\n",
       " \"\\n\\nI see at least three possible solutions:\\nA) Fix LoadDll and make applications deal with it.\\nB) Have a syscall.LoadDllSafe and change stdlib to use that (or even internal/syscall/windows.LoadDllSafe) and change nothing for custom user code.\\nC) Do nothing\\n\\nI think your solution A must include some plan for Go users on how to fix their breakage. I am worried they will just start copying runtime code. And some will make mistakes along the way. And maybe even copying code will not work for some reason or other.\\nAs to my preference, I like your B approach (we can do better than syscall.LoadDllSafe name). I can be arm twisted into doing C :-), but B is not much harder, and it will make all standard library code safe for this current issue. And it won't break any user code. We can mention new syscall.LoadDllSafe function in release notes, and let our users decide if it is important for their projects. syscall.LoadDllSafe could be a simple replacement for  , so it should be a trivial change for everyone who decides to follow our advice.\\nAlex\\n\",\n",
       " \"\\nI've updated https://go-review.googlesource.com/21140 to hopefully be non-controversial. It now makes sure that all DLLs loaded by Go itself are safe, but does nothing to protect users using   or   themselves.\\n\",\n",
       " '\\nThat seems like a good way forward.\\nWould exposing that to third party code via the sys-repo be fine? I can submit that, if it is ok.\\n',\n",
       " \"\\nTo write a proper test for https://golang.org/cl/21140, I would like a DLL which, when loaded, does something we can check easily in a test. Maybe it can write to stdout, or crash the process with a certain error code.\\n@mattn, could you provide such a minimal DLL & source code? From #14959 (comment) it looks like you know how to make them easily. I only have gomote+trybots for Windows testing. I don't have a Windows development machine at the moment. I found some information online about how to generate Windows DLLs from Linux which I can try otherwise.\\nOne DLL is probably fine, but maybe a 32-bit one and a 64-bit one would be better?\\n\",\n",
       " \"\\n@taruti, adding  /windows API for all the possibilities is not controversial. It's only new API in the standard library that we want to avoid. If you'd like to do the x/sys change(s) already, feel free. I'd be happy to review.\\n\",\n",
       " \"\\n\\nTo write a proper test for https://golang.org/cl/21140, I would like a DLL which, when loaded, does something we can check easily in a test.\\n\\nI think we already have TestStdcallAndCDeclCallbacks that does what you want. I wonder why the test didn't fail with your CL 21140 changes are applied.\\nAlex\\n\",\n",
       " \"\\nOh, nice.\\nMaybe the builders don't have gcc?\\n \\nWill investigate.\\n\",\n",
       " \"\\n\\nMaybe the builders don't have gcc?\\n\\nThey surely do. misc/cgo tests wouldn't run without gcc.\\nAlex\\n\",\n",
       " '\\n@alexbrainman, TestStdcallAndCDeclCallbacks didn\\'t fail because it\\'s using an absolute path to the DLL, which is unaffected by https://golang.org/cl/21140:\\n \\nI\\'ll write a new similar test using a base filename (\"test_bad.dll\") and verify it doesn\\'t search for it in the current directory once \"test_bad.dll\" is registered as requiring system32.\\n',\n",
       " '\\n  counterpart for discussion: https://go-review.googlesource.com/21388\\n',\n",
       " '\\nCL https://golang.org/cl/21388 mentions this issue.\\n',\n",
       " \"\\n@bradfitz Go should not paranoid when loading DLLs.\\nits not Go developer problem, its Window's user problem.\\nSearch Path behavior should remaining same https://msdn.microsoft.com/en-us/library/7d83bc18.aspx\\nits not Go's fault when loaded dll is fake, it is user fault executing unknown program in their environment.\\nI am Windows user, I consider this as a feature we can try and load newer dlls without the need to replace original system32 dlls. so udating software is much easier.\\n\\nevery downloaded file must be unblocked.\\nevery Windows user must have antivirus.\\n\\nWin User know it, and they already have their own guards.\\n\",\n",
       " \"\\n@blinksmith, we're only altering the DLL search path for DLLs used by Go.   will remain unchanged for other DLLs. It is a non-goal for people to be able to manually update their system DLLs in non-standard locations and have Go respect them from those paths. You should use the normal Windows system update mechanism.\\n /windows is getting a new   in https://golang.org/cl/21388 for having more control.\\n\",\n",
       " '\\nCL https://golang.org/cl/21428 mentions this issue.\\n',\n",
       " \"\\nWhat's left to fix this?\\n\",\n",
       " \"\\nPlease wait bradfitz. Now he's trying to buy Windows XP at Best Buy maybe.\\n\",\n",
       " \"\\nNothing's left, other than to ship Go1.6.1. @alexbrainman confirmed all.bat passes on his Windows XP machine, and the new test fails (skips) as expected on XP.\\n\",\n",
       " '\\nCL https://golang.org/cl/21639 mentions this issue.\\n',\n",
       " '\\nCL https://golang.org/cl/21680 mentions this issue.\\n',\n",
       " '\\nCL https://golang.org/cl/21696 mentions this issue.\\n',\n",
       " '\\nCL https://golang.org/cl/21697 mentions this issue.\\n',\n",
       " '\\nCL https://golang.org/cl/23025 mentions this issue.\\n',\n",
       " '\\n          runtime: Go 1.5.4/1.6.1 breaks running on Windows Nano Server\\n          #15286\\n',\n",
       " '\\n          Exit app from separate thread\\n          #216\\n',\n",
       " '\\nOutput of  :\\n \\nOutput of  :\\n \\nAdditional environment details (AWS, VirtualBox, physical, etc.):\\nRunning under VirtualBox through Vagrant.\\nSteps to reproduce the issue:\\n\\nOn docker host:\\n \\nIn the just-started container:\\n \\nIn another terminal on the same docker host:\\n \\n\\nDescribe the results you received:\\n \\nDescribe the results you expected:\\nIt should show my user id as 31337, not 0.\\nAdditional information you deem important (e.g. issue happens only occasionally):\\nThis could let image creators create malicious images which when run with a specific user id grant root in the container, and thus root to any mounted volumes.\\n',\n",
       " '\\nWhat happens if you try this on a regular linux box? i.e.\\n \\nThen\\n \\n',\n",
       " \"\\nThe behavior is the same as docker:\\n \\nHowever, even though this is similar to how docker operates, I still need the ability to run a container / exec something in a container with a specific user id, no matter the contents of the container's /etc/passwd.\\nAdditionally, an all-numeric username violates the username regex:\\n \\nThus the behavior of   should be to attempt to interpret the flag's argument as a numeric user id first, and if it is not numeric then to interpret it as a alphanumeric username second.\\n\",\n",
       " \"\\nI'm not sure we should change that; basically, it follows the way things work in Linux, i.e. request the system if there's a user with that name and if not, treat it as a uid.\\ncopying @NathanMcCauley @diogomonica for input on the security aspect of this\\n\",\n",
       " \"\\nYes, this looks like a bug in the   package.  I'll create an issue on runc and we will see about getting this fixed.\\n\",\n",
       " '\\nThis has been fixed by opencontainers/runc#708.\\n',\n",
       " '\\nAlright, so looks like we need to bump https://github.com/docker/docker/blob/master/hack/vendor.sh#L62\\n',\n",
       " '\\n          Numeric user id passed as user name if user name is numeric in /etc/passwd\\n          #695\\n',\n",
       " '\\n          vendor: bump runc to 2441732d6fcc0fb0a542671a4372e0c7bc99c19e\\n          #21665\\n',\n",
       " \"\\nMost shadow-related tools don't treat numeric ids as potential\\nusernames, so change our behaviour to match that. Previously, using an\\nexplicit specification like 111:222 could result in the UID and GID not\\nbeing 111 and 222 respectively (which is confusing).\\nFixes #695\\nSigned-off-by: Aleksa Sarai asarai@suse.de\\n\",\n",
       " \"\\n@tianon I know it's been a while, but I've refactored most of the code you wrote a few years ago. Want to take a look? :P\\n\",\n",
       " '\\n@dqminh Nits addressed. 😸\\n',\n",
       " \"\\nOther than the fact that we're hitting   at least once per every line in both   and   unnecessarily, this LGTM (and I'm OK with the implementation if there isn't a clean way to switch that code) 👍\\n\",\n",
       " '\\nThanks @cyphar !\\n',\n",
       " \"\\n@tianon I've addressed your concern about calling   too many times per line. Merging.\\n\",\n",
       " '\\nawesome, thanks all\\n',\n",
       " '\\n🤘\\n',\n",
       " '\\n          Numeric user id passed to --user interpreted as user name if user name is numeric in container  \\n          #21436\\n',\n",
       " '\\nThe cookie currently returns the openshift internal pod IP address.\\nThis is a security issue as an attacker can develop a map of the pods\\nin the cluster just by observing the returned cookie.\\nThis change returns a hash of the internal address and internal service\\nname to obfuscate the internal information. The service name is configured\\nwhen the service is created and is not visible to outside users. This\\nin combination with the internal ip:port is hashed and presented in the\\ncookie.\\naddresses: https://bugzilla.redhat.com/show_bug.cgi?id=1318796\\n',\n",
       " '\\nThis looks much better.  LGTM.\\n',\n",
       " '\\nCode LGTM  - If you could also add to the AddEndpoints test here: https://github.com/ramr/origin/blob/master/pkg/router/template/router_test.go#L68\\njust check that the   is set and matches expectations.\\n',\n",
       " \"\\nAs discussed over email - testing that the IdHash is valid looks fine but as re: the test failures for:\\n \\nThere is a check above the added code to ensure that if we add the same endpoints, we don't reload the router (return false from here basically since the config is unchanged). But since we now set the IdHash below this check, the 2 objects will never match up. So better to just move setting the IdHash to  .\\n\",\n",
       " '\\nAbove failure seems to be a flake:\\nI0406 16:14:51.933815   23883 client.go:320] Found registry v2 API at https://registry-1.docker.io/v2/\\n--- FAIL: TestRegistryClientImageV2-2 (0.12s)\\ndockerregistryclient_test.go:206: tag \"latest\" has not been set on repository \"openshift/origin\"\\nFAIL\\n',\n",
       " '\\n[test]\\n',\n",
       " '\\n[FLAKE:8466] problem is not in networking.\\n',\n",
       " '\\n[test]\\n',\n",
       " '\\n[merge] because looks like the last failure is #8480\\n',\n",
       " '\\n[TEST]\\n',\n",
       " '\\nlooks like you messed up the rebase quite badly...\\n',\n",
       " '\\neparis, help! I sent you email\\n',\n",
       " '\\napproved and [merge]  failed test looks unrelated.\\n',\n",
       " '\\nEvaluated for origin test up to 36c680b\\n',\n",
       " '\\n[merge] again because the failure is unrelated crap.\\n',\n",
       " '\\n@eparis Still failing. Could you try the merge again?\\n',\n",
       " '\\n[merge] with extreme prejudice\\n',\n",
       " \"\\nThis is [merge] try number 5\\n@danmcp I'm guessing there is nothing we can do about the aws m4.large failures?\\n\",\n",
       " \"\\n@eparis We have done some stuff.  Most of the tests are no longer using them (they didn't really need them anyway).  We can also switch zones if it continues to be a problem.  I need to (or someone does) to do a little research to pick the best one to move to if we are going to switch.\\n\",\n",
       " '\\ncontinuous-integration/openshift-jenkins/merge SUCCESS (https://ci.openshift.redhat.com/jenkins/job/merge_pull_requests_origin/5637/) (Image: devenv-rhel7_3997)\\n',\n",
       " '\\ncontinuous-integration/openshift-jenkins/test FAILURE (https://ci.openshift.redhat.com/jenkins/job/test_pr_origin/3106/)\\n',\n",
       " '\\n[merge] you silly PR. merge!\\n',\n",
       " '\\nEvaluated for origin merge up to 36c680b\\n',\n",
       " '\\nThe container that is launched by s2i (outside of Kube control) currently allows an escalation of privilege via su or sudo. We can prevent this by dropping the same capabilities that are dropped for regular pods when running under the restricted SCC.\\nFixes BZ 1315187\\n',\n",
       " '\\n@bparees @mfojtik @liggitt\\n',\n",
       " '\\n[testonlyextended][extended:core(builds)]\\n',\n",
       " '\\nEvaluated for origin testonlyextended up to 26e798b\\n',\n",
       " '\\ncontinuous-integration/openshift-jenkins/testonlyextended FAILURE (https://ci.openshift.redhat.com/jenkins/job/test_pr_origin/1930/) (Extended Tests: core(builds))\\n',\n",
       " '\\nI think you can avoid the builder image build by just including the customized assemble script as \".s2i/bin\" in the context dir you upload as the binary input, no?\\n',\n",
       " \"\\nI also set the root password in the builder image and install 'expect'\\n\",\n",
       " '\\nso you do.  lgtm, pending resolution to the tests failing.\\n',\n",
       " '\\n@bparees, I opened issues for the tests that failed:\\n#7904\\n#7906\\n#7910\\n#7911\\nnone of those are related to this change.\\n[test]\\n',\n",
       " '\\nEvaluated for origin test up to 26e798b\\n',\n",
       " '\\n@csrwng thanks, lgtm.\\n[merge]\\n',\n",
       " '\\ncontinuous-integration/openshift-jenkins/merge SUCCESS (https://ci.openshift.redhat.com/jenkins/job/merge_pull_requests_origin/5261/) (Image: devenv-rhel7_3668)\\n',\n",
       " '\\nEvaluated for origin merge up to 26e798b\\n',\n",
       " '\\ncontinuous-integration/openshift-jenkins/test FAILURE (https://ci.openshift.redhat.com/jenkins/job/test_pr_origin/1965/) (Extended Tests: core(builds))\\n',\n",
       " \"\\nCurrently, patch will check admission control with an empty object and if it passes, then will proceed to update the object with the patch. Admission control plugins don't get a chance to see/validate what is actually going to be updated.\\n\",\n",
       " '\\n@lavalamp @deads2k\\n',\n",
       " '\\n@derekwaynecarr\\n',\n",
       " '\\n@smarterclayton @kubernetes/goog-csi @kubernetes/rh-cluster-infra is there a group for API server?\\n@kubernetes/kube-iam this affects field level authorization.\\n',\n",
       " '\\nI think I want to apply the admission chain twice.  Once for patch as-is and once for \"update\" with the patched object.\\nThis is necessary because admission may mutate the patch itself before its applied, so you can\\'t patch the object ahead of time.\\n',\n",
       " '\\nWhy?\\n',\n",
       " '\\nIf you check for the patch as is admission control plugins would have to special case objects that are not complete.\\n',\n",
       " '\\n\\nIf you check for the patch as is admission control plugins would have to special case objects that are not complete.\\n\\nSince the patch itself may mutate during the admission process, the \"patched\"  object created at the beginning of the admission change is not guaranteed to be correct, so it would be incorrect for an admission controller to do any work against the \"patched\" object.\\n',\n",
       " '\\nIt may make sense then to have a separate operation (Patch?) for admission control plugins to explicitly check / mutate patches and not special case complete/incomplete objects on update.\\n',\n",
       " '\\n@kubernetes/sig-api-machinery\\nOn Mon, Jan 11, 2016 at 10:54 AM, Cesar Wong notifications@github.com\\nwrote:\\n\\nIt may make sense then to have a separate operation (Patch?) for admission\\ncontrol plugins to explicitly check / mutate patches and not special case\\ncomplete/incomplete objects on update.\\n—\\nReply to this email directly or view it on GitHub\\n#19479 (comment)\\n.\\n\\n',\n",
       " '\\nUpdate is a totally separate kind of operation from create, and IMO needs to have a different admission mechanism. Specifically, I think you need an admission call that passes the old object and the proposed object (patched, if appropriate).\\nOtherwise, you have no way to forbid certain transitions. Just because the initial and final states are independently valid, it does not necessarily mean that the transition between them is allowed.\\n',\n",
       " '\\n          Include update operation in build admission controller\\n          #6576\\n',\n",
       " '\\n          make patch call update admission chain after applying the patch\\n          #19481\\n',\n",
       " \"\\n          I've found 3 vulnerabilities of kubernetes on NVD,did they solved?\\n          #23860\\n\",\n",
       " '\\nIf I apply the policy changes to restrict certain build strategies, I can create a BC with an allowed strategy and then edit the BC to use a restricted strategy, that edit should fail.  Instead it allows the modification.  It does still correctly prevent the builds from being launched.\\n',\n",
       " \"\\n@bparees or @jwforres can you change the priority of this issue to P1? It allows escalating privileges on a node. You don't need to explicitly be able to create a build once you've created a build config with a forbidden type. An image change trigger can do that for you.\\n\",\n",
       " '\\n          Include update operation in build admission controller\\n          #6576\\n',\n",
       " '\\n \\nI get different results whether I run it in amd64 mode or 386 mode\\n \\nThe first one is correct (you can verify this with python thus)\\n \\nThe playground also gives the incorrect results.\\nTested with go 1.5.1 and tip\\n \\n',\n",
       " \"\\nJust noticing that you @ncw closed this already. Not a bug? (Haven't looked into it yet).\\n\",\n",
       " \"\\nThis is a legitimate issue.  I'm seeing the same behavior with different values:\\n \\nOutput:\\n \\nresult: 77c873fcee4663289da06a660417b6a9831c77875632199b2d1c0f4372606c84\\n \\nresult: ef03bdbf3d5e1c37142f762042f3c49d3e1ba5a71ba1e238c54aa913b00fbe4f\\nEDIT: I should note the amd64 result is the correct one.\\n\",\n",
       " \"\\nYes, it's a real bug. I am preparing a fix CL.\\n\",\n",
       " '\\nCL https://golang.org/cl/17673 mentions this issue.\\n',\n",
       " '\\nCL https://golang.org/cl/17672 mentions this issue.\\n',\n",
       " '\\nI wonder if this is related to this case: http://play.golang.org/p/QVWwgKMdCu ?\\nI expect result to be equal zero, but I see result equal M.\\nShould I open separate issue for this matter?\\nThanks.\\n',\n",
       " '\\n@ysmolsky, thanks. I will file a new issue.\\n',\n",
       " '\\nThanks, Russ!\\n',\n",
       " '\\nCL https://golang.org/cl/18585 mentions this issue.\\n',\n",
       " '\\n          math/big: Exp(x, x, x) returns x sometimes (instead of 0)\\n          #13907\\n',\n",
       " '\\n          website: release history links to missing \"Go1.5.3\" milestone\\n          #14687\\n',\n",
       " '\\nWhen checking the log URL for a pod container we must validate the container name if provided, otherwise the method will return an URL that is actually not valid and results in an error when called, e.g.  .\\n',\n",
       " '\\nLabelling this PR as size/L\\n',\n",
       " '\\nGCE e2e test build/test passed for commit b2f7d3a.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nGCE e2e test build/test passed for commit 44bf2a6.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nGCE e2e build/test failed for commit f558dd5.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nGCE e2e test build/test passed for commit 325c5a2.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nGCE e2e test build/test passed for commit bd90254.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nLgtm, update with feedback from @kargakis?\\n',\n",
       " '\\n@k8s-bot test this [submit-queue is verifying that this PR is safe to merge]\\n',\n",
       " '\\nGCE e2e build/test failed for commit bd90254.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nBuild error\\n \\n@k8s-bot test this\\n',\n",
       " '\\nGCE e2e build/test failed for commit bd90254.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nPR changed after LGTM, removing LGTM.\\n',\n",
       " '\\nUpdated addressing @kargakis comments, @liggitt needs lgtm again.\\n',\n",
       " '\\nTeamCity OSS :: Kubernetes Mesos :: 4 - Smoke Tests Build 7162 outcome was SUCCESS\\nSummary: Tests passed: 1, ignored: 204 Build time: 00:05:16\\n',\n",
       " '\\nGCE e2e test build/test passed for commit afd5649.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\n@k8s-bot test this [submit-queue is verifying that this PR is safe to merge]\\n',\n",
       " '\\nGCE e2e build/test failed for commit afd5649.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\n@k8s-bot e2e test this please\\n',\n",
       " '\\nGCE e2e test build/test passed for commit afd5649.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\n@k8s-bot test this [submit-queue is verifying that this PR is safe to merge]\\n',\n",
       " '\\nGCE e2e test build/test passed for commit afd5649.\\n\\nBuild Log\\nTest Artifacts\\nInternal Jenkins Results\\n\\n',\n",
       " '\\nAutomatic merge from submit-queue\\n',\n",
       " '\\n          UPSTREAM: 17886: pod log location must validate container if provided\\n          #6113\\n',\n",
       " '\\n          Pod log location must validate container if provided\\n          #17953\\n',\n",
       " '\\n          Pod log location must validate container if provided\\n          #17954\\n',\n",
       " \"\\nEnv\\n \\nNOTE: I couldn't reproduce this issue with OSE v3.0.1.0 due to another error.\\nIssue:\\n\\nWe can kill OpenShift process by sending request with invalid json file.\\nPlease see following steps.\\n\\nReproduce steps\\nstep-1. Start openshift origin with standalone mode, and create route and docker-registry. (Followed with here)\\nstep-2. Send invalid json file by my origin-killer.json\\n \\nstep-3. You can see go panic and stop the OpenShift process\\nThe log is here: https://kenjiro.fedorapeople.org/misc/logs/origin.log (Too long, please check from the bottom.)\\n\",\n",
       " '\\n \\n',\n",
       " \"\\nshould fix the assumption that strategy guaranteed a non-nil params field, but also find out why a panic handler wasn't catching this\\n\",\n",
       " '\\nP0 - we may need to hot fix\\n',\n",
       " '\\nWe may have lost the panic handler accidently in the API installer.  Could be upstream too.\\n',\n",
       " '\\n          UPSTREAM: 13317: Recover panics in finishRequest goroutine\\n          #4416\\n',\n",
       " '\\n \\n',\n",
       " '\\nThese are the router credentials currently stored in envvars. Same exists for the registry pod\\n',\n",
       " '\\nWhat log level should we be defaulting users to at this point?\\n',\n",
       " '\\n4 is \"debug\", 2 is \"normal verbosity\", 3 is \"more than normal\".\\n',\n",
       " \"\\n@liggitt that is fine, but should it be logging them to the nodes?\\n@sdodson I don't think log level matters, it should not be logging private keys.\\n\",\n",
       " '\\n@wshearn agreed. My question was somewhat tangential, sorry.\\n',\n",
       " '\\nShould we expect envvars to contain secret values?\\n',\n",
       " '\\n@liggitt What about generating a secret store and mounting that into the container? That could allow people to still easily overwrite the secrets if they want while still providing some security around them.\\n',\n",
       " '\\nConverting registry/router to use service account credentials (as secrets) is already planned, just not done yet\\n',\n",
       " '\\nFound another place this is being spit out (probably stored in the same place on the backend)\\n \\n',\n",
       " '\\nRight, the root cause is storing the cert/key as envvars in the pod, which is what needs to stop.\\n',\n",
       " \"\\n--credentials has been deprecated for both router and registry commands. I'd like to stop generating the cert-based credentials for the register and router post-1.2, and remove the --credentials option entirely by 1.3\\n\",\n",
       " \"\\nDeprecated in 1.2? it's littered all over our docs currently.\\n\",\n",
       " \"\\nIt's still present, functional, and supported, but isn't necessary and is discouraged. Docs still need updating, on my list.\\n\",\n",
       " '\\nWait, what is 1.2 and 1.3? The git tags show the latest stable release as v1.1.6\\n',\n",
       " '\\n\\nwhat is 1.2 and 1.3\\n\\nthe future :)\\n',\n",
       " '\\nAh, ok. The way @sdodson said \"depricated in 1.2?\" sounded past tense and I was confused. Thanks :)\\n',\n",
       " \"\\nSo FYI, I stumbled on that while looking for bug, and asked for a CVE to be assigned:\\nhttp://www.openwall.com/lists/oss-security/2016/07/13/9\\nAnswer:\\nhttp://www.openwall.com/lists/oss-security/2016/07/13/10\\nSo that's CVE-2015-8945.\\n\",\n",
       " '\\n          Remove --credentials flags, stop generating router/registry client certs\\n          #10830\\n']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = extract_issues(issues_links[6])\n",
    "d = extract_issues(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorz = TfidfVectorizer(stop_words = stop, \n",
    "                          use_idf=True, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorz.fit_transform(refine_text(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2310 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 510 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2310)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=22,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=22, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 2.42912981e-02, 2.42912981e-02, 2.42912981e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 6.46039187e-02, 9.09170758e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 5.45502455e-02, 3.63668303e-02, 3.63668303e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 3.63668303e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 4.78235651e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 2.42912981e-02, 2.42912981e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       3.63668303e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 2.42912981e-02,\n",
       "       2.42912981e-02, 2.42912981e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       5.45502455e-02, 1.81834152e-02, 1.81834152e-02, 3.63668303e-02,\n",
       "       3.63668303e-02, 1.05994101e-15, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       7.27336607e-02, 5.45502455e-02, 3.63668303e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 7.27336607e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       5.45502455e-02, 5.45502455e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       2.42912981e-02, 2.42912981e-02, 2.42912981e-02, 7.96064983e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 6.52704850e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 6.46039187e-02, 6.46039187e-02, 3.63668303e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 1.16204957e-01, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.29207837e-01, 6.46039187e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       7.27336607e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       3.63668303e-02, 3.63668303e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 3.31245157e-01,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 6.52704850e-02, 6.46039187e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 7.27336607e-02, 3.63668303e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       5.45502455e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 3.63668303e-02, 3.63668303e-02,\n",
       "       3.63668303e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 2.42912981e-02, 2.42912981e-02,\n",
       "       2.42912981e-02, 3.88589211e-01, 3.31245157e-01, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       6.52704850e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       6.46039187e-02, 1.81834152e-02, 1.81834152e-02, 3.63668303e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 3.63668303e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.16204957e-01, 1.81834152e-02, 1.81834152e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 2.42912981e-02, 2.42912981e-02, 2.42912981e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       2.42912981e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 3.63668303e-02, 3.63668303e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.34875518e-02, 2.42912981e-02, 2.42912981e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.29207837e-01, 6.46039187e-02,\n",
       "       6.46039187e-02, 6.46039187e-02, 6.46039187e-02, 9.09170758e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 7.27336607e-02, 3.63668303e-02,\n",
       "       3.63668303e-02, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       1.21020482e-01, 6.46039187e-02, 6.46039187e-02, 6.46039187e-02,\n",
       "       6.46039187e-02, 2.42912981e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 3.63668303e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02,\n",
       "       1.81834152e-02, 1.81834152e-02, 1.81834152e-02, 1.05994101e-15,\n",
       "       1.05994101e-15, 1.81834152e-02, 1.81834152e-02, 1.81834152e-02])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "terms = vectorz.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    termInComp = zip(terms,comp)\n",
    "    sortedterms = sorted(termInComp,key=lambda x:x[1], reverse=True)[:30]\n",
    "    print(\"Concept: \", i)\n",
    "    for term in sortedterms:\n",
    "        print(term[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
